#!/usr/bin/env python3
"""
AetherFlow æ€§èƒ½åŸºå‡†æµ‹è¯•

å¯¹æ¯”ThreadLocalSingletonå’ŒSingletonä¸¤ç§å¹¶å‘æ¨¡å¼çš„æ€§èƒ½ç‰¹å¾ï¼Œ
æä¾›é‡åŒ–çš„æ€§èƒ½æ•°æ®å¸®åŠ©ç”¨æˆ·åšå‡ºæ¶æ„å†³ç­–ã€‚
"""

import time
import threading
import statistics
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass
from typing import List, Dict, Any, Callable
from dependency_injector import containers, providers

import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))
from src.aetherflow import node, BaseFlowContext


@dataclass
class BenchmarkResult:
    """åŸºå‡†æµ‹è¯•ç»“æœ"""
    name: str
    mode: str  # "thread_local" or "shared"
    total_time: float
    operations_per_second: float
    avg_operation_time: float
    median_operation_time: float
    min_operation_time: float
    max_operation_time: float
    memory_usage_mb: float
    error_rate: float
    thread_count: int
    operations_per_thread: int


class LightweightService:
    """è½»é‡çº§æœåŠ¡ï¼Œç”¨äºæµ‹è¯•åŸºç¡€æ€§èƒ½"""
    
    def __init__(self):
        self.counter = 0
        self.thread_id = threading.current_thread().ident
        self.creation_time = time.time()
    
    def simple_operation(self, data):
        """ç®€å•æ“ä½œ"""
        self.counter += 1
        return {'result': data * 2 + self.counter, 'thread_id': self.thread_id}


class HeavyweightService:
    """é‡é‡çº§æœåŠ¡ï¼Œç”¨äºæµ‹è¯•å¤æ‚åœºæ™¯æ€§èƒ½"""
    
    def __init__(self):
        self.cache = {}
        self.computation_count = 0
        self.thread_id = threading.current_thread().ident
        self.lock = threading.Lock()  # ä»…ç”¨äºsharedæ¨¡å¼
        
        # æ¨¡æ‹Ÿé‡é‡çº§åˆå§‹åŒ–
        time.sleep(0.001)
    
    def heavy_operation(self, data):
        """é‡è®¡ç®—æ“ä½œ"""
        # æ¨¡æ‹ŸCPUå¯†é›†è®¡ç®—
        result = 0
        for i in range(1000):
            result += data * i
        
        self.computation_count += 1
        self.cache[f"result_{data}"] = result
        
        return {
            'result': result,
            'computation_count': self.computation_count,
            'thread_id': self.thread_id,
            'cache_size': len(self.cache)
        }
    
    def thread_safe_heavy_operation(self, data):
        """çº¿ç¨‹å®‰å…¨çš„é‡è®¡ç®—æ“ä½œï¼ˆç”¨äºsharedæ¨¡å¼ï¼‰"""
        result = 0
        for i in range(1000):
            result += data * i
        
        with self.lock:
            self.computation_count += 1
            self.cache[f"result_{data}"] = result
            computation_count = self.computation_count
            cache_size = len(self.cache)
        
        return {
            'result': result,
            'computation_count': computation_count,
            'thread_id': self.thread_id,
            'cache_size': cache_size
        }


# çº¿ç¨‹æœ¬åœ°ä¸Šä¸‹æ–‡
class ThreadLocalContext(BaseFlowContext):
    lightweight_service = providers.ThreadLocalSingleton(LightweightService)
    heavyweight_service = providers.ThreadLocalSingleton(HeavyweightService)


# å…±äº«çŠ¶æ€ä¸Šä¸‹æ–‡
class SharedContext(BaseFlowContext):
    lightweight_service = providers.Singleton(LightweightService)
    heavyweight_service = providers.Singleton(HeavyweightService)


# æµ‹è¯•èŠ‚ç‚¹
@node
def lightweight_node_tl(data, lightweight_service: LightweightService):
    """è½»é‡çº§èŠ‚ç‚¹ - çº¿ç¨‹æœ¬åœ°ç‰ˆæœ¬"""
    return lightweight_service.simple_operation(data)


@node
def lightweight_node_shared(data, lightweight_service: LightweightService):
    """è½»é‡çº§èŠ‚ç‚¹ - å…±äº«ç‰ˆæœ¬"""
    return lightweight_service.simple_operation(data)


@node
def heavyweight_node_tl(data, heavyweight_service: HeavyweightService):
    """é‡é‡çº§èŠ‚ç‚¹ - çº¿ç¨‹æœ¬åœ°ç‰ˆæœ¬"""
    return heavyweight_service.heavy_operation(data)


@node
def heavyweight_node_shared(data, heavyweight_service: HeavyweightService):
    """é‡é‡çº§èŠ‚ç‚¹ - å…±äº«ç‰ˆæœ¬"""
    return heavyweight_service.thread_safe_heavy_operation(data)


class PerformanceBenchmark:
    """æ€§èƒ½åŸºå‡†æµ‹è¯•å¥—ä»¶"""
    
    def __init__(self):
        self.results = []
    
    def measure_memory_usage(self) -> float:
        """æµ‹é‡å†…å­˜ä½¿ç”¨é‡ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        try:
            import psutil
            import os
            process = psutil.Process(os.getpid())
            return process.memory_info().rss / 1024 / 1024  # MB
        except ImportError:
            return 0.0  # å¦‚æœæ²¡æœ‰psutilï¼Œè¿”å›0
    
    def benchmark_operation(
        self,
        name: str,
        mode: str,
        node_func: Callable,
        context: BaseFlowContext,
        thread_count: int,
        operations_per_thread: int
    ) -> BenchmarkResult:
        """åŸºå‡†æµ‹è¯•å•ä¸ªæ“ä½œ"""
        print(f"ğŸƒ è¿è¡ŒåŸºå‡†æµ‹è¯•: {name} ({mode}, {thread_count} threads, {operations_per_thread} ops/thread)")
        
        operation_times = []
        errors = 0
        
        def worker(worker_id):
            worker_times = []
            worker_errors = 0
            
            for i in range(operations_per_thread):
                start_time = time.time()
                try:
                    result = node_func.run({'data': worker_id * 1000 + i}, context)
                    end_time = time.time()
                    worker_times.append(end_time - start_time)
                except Exception as e:
                    worker_errors += 1
                    print(f"âŒ Worker {worker_id} error: {e}")
            
            return worker_times, worker_errors
        
        # æµ‹é‡å†…å­˜ä½¿ç”¨ï¼ˆå¼€å§‹å‰ï¼‰
        memory_before = self.measure_memory_usage()
        
        # æ‰§è¡ŒåŸºå‡†æµ‹è¯•
        start_time = time.time()
        
        with ThreadPoolExecutor(max_workers=thread_count) as executor:
            futures = [executor.submit(worker, i) for i in range(thread_count)]
            results = [future.result() for future in as_completed(futures)]
        
        end_time = time.time()
        
        # æµ‹é‡å†…å­˜ä½¿ç”¨ï¼ˆç»“æŸåï¼‰
        memory_after = self.measure_memory_usage()
        memory_usage = max(0, memory_after - memory_before)
        
        # æ”¶é›†æ‰€æœ‰æ“ä½œæ—¶é—´å’Œé”™è¯¯
        for worker_times, worker_errors in results:
            operation_times.extend(worker_times)
            errors += worker_errors
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        total_time = end_time - start_time
        total_operations = len(operation_times)
        operations_per_second = total_operations / total_time if total_time > 0 else 0
        error_rate = errors / (total_operations + errors) if (total_operations + errors) > 0 else 0
        
        return BenchmarkResult(
            name=name,
            mode=mode,
            total_time=total_time,
            operations_per_second=operations_per_second,
            avg_operation_time=statistics.mean(operation_times) if operation_times else 0,
            median_operation_time=statistics.median(operation_times) if operation_times else 0,
            min_operation_time=min(operation_times) if operation_times else 0,
            max_operation_time=max(operation_times) if operation_times else 0,
            memory_usage_mb=memory_usage,
            error_rate=error_rate,
            thread_count=thread_count,
            operations_per_thread=operations_per_thread
        )
    
    def run_lightweight_benchmarks(self):
        """è¿è¡Œè½»é‡çº§æ“ä½œåŸºå‡†æµ‹è¯•"""
        print("\nğŸ“Š è½»é‡çº§æ“ä½œæ€§èƒ½æµ‹è¯•")
        print("=" * 50)
        
        # çº¿ç¨‹æœ¬åœ°æ¨¡å¼
        tl_result = self.benchmark_operation(
            name="Lightweight Operation",
            mode="thread_local",
            node_func=lightweight_node_tl,
            context=ThreadLocalContext(),
            thread_count=8,
            operations_per_thread=1000
        )
        self.results.append(tl_result)
        
        # å…±äº«æ¨¡å¼
        shared_result = self.benchmark_operation(
            name="Lightweight Operation",
            mode="shared",
            node_func=lightweight_node_shared,
            context=SharedContext(),
            thread_count=8,
            operations_per_thread=1000
        )
        self.results.append(shared_result)
        
        # å¯¹æ¯”ç»“æœ
        speedup = tl_result.operations_per_second / shared_result.operations_per_second if shared_result.operations_per_second > 0 else 0
        print(f"ğŸ’¨ çº¿ç¨‹æœ¬åœ°æ¨¡å¼: {tl_result.operations_per_second:.0f} ops/sec")
        print(f"ğŸ”„ å…±äº«çŠ¶æ€æ¨¡å¼: {shared_result.operations_per_second:.0f} ops/sec")
        print(f"âš¡ æ€§èƒ½å€æ•°: {speedup:.2f}x")
    
    def run_heavyweight_benchmarks(self):
        """è¿è¡Œé‡é‡çº§æ“ä½œåŸºå‡†æµ‹è¯•"""
        print("\nğŸ“Š é‡é‡çº§æ“ä½œæ€§èƒ½æµ‹è¯•")
        print("=" * 50)
        
        # çº¿ç¨‹æœ¬åœ°æ¨¡å¼
        tl_result = self.benchmark_operation(
            name="Heavyweight Operation",
            mode="thread_local",
            node_func=heavyweight_node_tl,
            context=ThreadLocalContext(),
            thread_count=4,
            operations_per_thread=100
        )
        self.results.append(tl_result)
        
        # å…±äº«æ¨¡å¼
        shared_result = self.benchmark_operation(
            name="Heavyweight Operation",
            mode="shared",
            node_func=heavyweight_node_shared,
            context=SharedContext(),
            thread_count=4,
            operations_per_thread=100
        )
        self.results.append(shared_result)
        
        # å¯¹æ¯”ç»“æœ
        speedup = tl_result.operations_per_second / shared_result.operations_per_second if shared_result.operations_per_second > 0 else 0
        print(f"ğŸ’¨ çº¿ç¨‹æœ¬åœ°æ¨¡å¼: {tl_result.operations_per_second:.0f} ops/sec")
        print(f"ğŸ”„ å…±äº«çŠ¶æ€æ¨¡å¼: {shared_result.operations_per_second:.0f} ops/sec")
        print(f"âš¡ æ€§èƒ½å€æ•°: {speedup:.2f}x")
    
    def run_scalability_test(self):
        """è¿è¡Œå¯æ‰©å±•æ€§æµ‹è¯•"""
        print("\nğŸ“Š å¯æ‰©å±•æ€§æµ‹è¯•")
        print("=" * 50)
        
        thread_counts = [1, 2, 4, 8, 16]
        
        for thread_count in thread_counts:
            print(f"\nğŸ§µ æµ‹è¯• {thread_count} ä¸ªçº¿ç¨‹:")
            
            # çº¿ç¨‹æœ¬åœ°æ¨¡å¼
            tl_result = self.benchmark_operation(
                name=f"Scalability Test ({thread_count} threads)",
                mode="thread_local",
                node_func=lightweight_node_tl,
                context=ThreadLocalContext(),
                thread_count=thread_count,
                operations_per_thread=500
            )
            self.results.append(tl_result)
            
            # å…±äº«æ¨¡å¼
            shared_result = self.benchmark_operation(
                name=f"Scalability Test ({thread_count} threads)",
                mode="shared",
                node_func=lightweight_node_shared,
                context=SharedContext(),
                thread_count=thread_count,
                operations_per_thread=500
            )
            self.results.append(shared_result)
            
            print(f"   çº¿ç¨‹æœ¬åœ°: {tl_result.operations_per_second:.0f} ops/sec")
            print(f"   å…±äº«çŠ¶æ€: {shared_result.operations_per_second:.0f} ops/sec")
    
    def run_memory_usage_test(self):
        """è¿è¡Œå†…å­˜ä½¿ç”¨æµ‹è¯•"""
        print("\nğŸ“Š å†…å­˜ä½¿ç”¨å¯¹æ¯”æµ‹è¯•")
        print("=" * 50)
        
        # æµ‹è¯•ä¸åŒçº¿ç¨‹æ•°ä¸‹çš„å†…å­˜ä½¿ç”¨
        for thread_count in [1, 4, 8]:
            print(f"\nğŸ’¾ {thread_count} ä¸ªçº¿ç¨‹çš„å†…å­˜ä½¿ç”¨:")
            
            # çº¿ç¨‹æœ¬åœ°æ¨¡å¼
            tl_result = self.benchmark_operation(
                name=f"Memory Test ({thread_count} threads)",
                mode="thread_local",
                node_func=heavyweight_node_tl,
                context=ThreadLocalContext(),
                thread_count=thread_count,
                operations_per_thread=50
            )
            
            # å…±äº«æ¨¡å¼
            shared_result = self.benchmark_operation(
                name=f"Memory Test ({thread_count} threads)",
                mode="shared",
                node_func=heavyweight_node_shared,
                context=SharedContext(),
                thread_count=thread_count,
                operations_per_thread=50
            )
            
            print(f"   çº¿ç¨‹æœ¬åœ°: {tl_result.memory_usage_mb:.1f} MB")
            print(f"   å…±äº«çŠ¶æ€: {shared_result.memory_usage_mb:.1f} MB")
            
            self.results.append(tl_result)
            self.results.append(shared_result)
    
    def generate_report(self):
        """ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š"""
        print("\nğŸ“‹ æ€§èƒ½åŸºå‡†æµ‹è¯•æŠ¥å‘Š")
        print("=" * 80)
        
        # æŒ‰ç±»åˆ«ç»„ç»‡ç»“æœ
        lightweight_results = [r for r in self.results if "Lightweight" in r.name]
        heavyweight_results = [r for r in self.results if "Heavyweight" in r.name]
        scalability_results = [r for r in self.results if "Scalability" in r.name]
        memory_results = [r for r in self.results if "Memory" in r.name]
        
        # è½»é‡çº§æ“ä½œæ€»ç»“
        if lightweight_results:
            print("\nğŸš€ è½»é‡çº§æ“ä½œæ€§èƒ½æ€»ç»“:")
            tl_lightweight = [r for r in lightweight_results if r.mode == "thread_local"]
            shared_lightweight = [r for r in lightweight_results if r.mode == "shared"]
            
            if tl_lightweight and shared_lightweight:
                tl_avg = statistics.mean([r.operations_per_second for r in tl_lightweight])
                shared_avg = statistics.mean([r.operations_per_second for r in shared_lightweight])
                improvement = (tl_avg / shared_avg - 1) * 100 if shared_avg > 0 else 0
                print(f"   çº¿ç¨‹æœ¬åœ°å¹³å‡: {tl_avg:.0f} ops/sec")
                print(f"   å…±äº«çŠ¶æ€å¹³å‡: {shared_avg:.0f} ops/sec")
                print(f"   æ€§èƒ½æå‡: {improvement:+.1f}%")
        
        # é‡é‡çº§æ“ä½œæ€»ç»“
        if heavyweight_results:
            print("\nğŸ‹ï¸ é‡é‡çº§æ“ä½œæ€§èƒ½æ€»ç»“:")
            tl_heavyweight = [r for r in heavyweight_results if r.mode == "thread_local"]
            shared_heavyweight = [r for r in heavyweight_results if r.mode == "shared"]
            
            if tl_heavyweight and shared_heavyweight:
                tl_avg = statistics.mean([r.operations_per_second for r in tl_heavyweight])
                shared_avg = statistics.mean([r.operations_per_second for r in shared_heavyweight])
                improvement = (tl_avg / shared_avg - 1) * 100 if shared_avg > 0 else 0
                print(f"   çº¿ç¨‹æœ¬åœ°å¹³å‡: {tl_avg:.0f} ops/sec")
                print(f"   å…±äº«çŠ¶æ€å¹³å‡: {shared_avg:.0f} ops/sec")
                print(f"   æ€§èƒ½æå‡: {improvement:+.1f}%")
        
        # å¯æ‰©å±•æ€§æ€»ç»“
        if scalability_results:
            print("\nğŸ“ˆ å¯æ‰©å±•æ€§åˆ†æ:")
            thread_counts = sorted(set(r.thread_count for r in scalability_results))
            
            for thread_count in thread_counts:
                tl_results = [r for r in scalability_results if r.thread_count == thread_count and r.mode == "thread_local"]
                shared_results = [r for r in scalability_results if r.thread_count == thread_count and r.mode == "shared"]
                
                if tl_results and shared_results:
                    tl_ops = tl_results[0].operations_per_second
                    shared_ops = shared_results[0].operations_per_second
                    ratio = tl_ops / shared_ops if shared_ops > 0 else 0
                    print(f"   {thread_count:2d} çº¿ç¨‹: çº¿ç¨‹æœ¬åœ° {tl_ops:6.0f} ops/sec, å…±äº« {shared_ops:6.0f} ops/sec (æ¯”å€¼: {ratio:.2f})")
        
        # å†…å­˜ä½¿ç”¨æ€»ç»“
        if memory_results:
            print("\nğŸ’¾ å†…å­˜ä½¿ç”¨åˆ†æ:")
            thread_counts = sorted(set(r.thread_count for r in memory_results))
            
            for thread_count in thread_counts:
                tl_results = [r for r in memory_results if r.thread_count == thread_count and r.mode == "thread_local"]
                shared_results = [r for r in memory_results if r.thread_count == thread_count and r.mode == "shared"]
                
                if tl_results and shared_results:
                    tl_mem = tl_results[0].memory_usage_mb
                    shared_mem = shared_results[0].memory_usage_mb
                    ratio = tl_mem / shared_mem if shared_mem > 0 else 0
                    print(f"   {thread_count:2d} çº¿ç¨‹: çº¿ç¨‹æœ¬åœ° {tl_mem:5.1f} MB, å…±äº« {shared_mem:5.1f} MB (æ¯”å€¼: {ratio:.2f})")
        
        print("\nğŸ¯ å…³é”®å‘ç°:")
        print("   â€¢ çº¿ç¨‹æœ¬åœ°æ¨¡å¼åœ¨è½»é‡çº§æ“ä½œä¸­é€šå¸¸æœ‰æ›´å¥½çš„æ€§èƒ½")
        print("   â€¢ é‡é‡çº§æ“ä½œä¸­ä¸¤ç§æ¨¡å¼å·®å¼‚è¾ƒå°")
        print("   â€¢ çº¿ç¨‹æœ¬åœ°æ¨¡å¼ä½¿ç”¨æ›´å¤šå†…å­˜ä½†é¿å…äº†é”ç«äº‰")
        print("   â€¢ å…±äº«æ¨¡å¼åœ¨ä½å¹¶å‘æ—¶æœ‰å†…å­˜ä¼˜åŠ¿")
        print("   â€¢ é«˜å¹¶å‘åœºæ™¯ä¸‹çº¿ç¨‹æœ¬åœ°æ¨¡å¼ä¼˜åŠ¿æ˜æ˜¾")


def run_performance_benchmarks():
    """è¿è¡Œå®Œæ•´çš„æ€§èƒ½åŸºå‡†æµ‹è¯•"""
    print("ğŸ AetherFlow æ€§èƒ½åŸºå‡†æµ‹è¯•å¼€å§‹")
    print("=" * 60)
    
    benchmark = PerformanceBenchmark()
    
    try:
        # è¿è¡Œå„ç±»æµ‹è¯•
        benchmark.run_lightweight_benchmarks()
        benchmark.run_heavyweight_benchmarks()
        benchmark.run_scalability_test()
        benchmark.run_memory_usage_test()
        
        # ç”ŸæˆæŠ¥å‘Š
        benchmark.generate_report()
        
        print(f"\nâœ… åŸºå‡†æµ‹è¯•å®Œæˆï¼å…±æ‰§è¡Œäº† {len(benchmark.results)} ä¸ªæµ‹è¯•åœºæ™¯ã€‚")
        return True
        
    except Exception as e:
        print(f"\nâŒ åŸºå‡†æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == '__main__':
    success = run_performance_benchmarks()
    exit(0 if success else 1)