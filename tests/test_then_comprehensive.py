#!/usr/bin/env python3
"""
test_then_comprehensive.py - Nodeçš„thenæ–¹æ³•ç»¼åˆæµ‹è¯•
åŒ…å«ï¼šåŸºæœ¬thenåŠŸèƒ½ã€é“¾å¼è°ƒç”¨ã€ä¾èµ–æ³¨å…¥ã€context/stateä¼ é€’çš„å®Œæ•´æµ‹è¯•
"""

from dataclasses import dataclass
from typing import Dict, List, Tuple, Optional
from pydantic import BaseModel, Field, validator
from dependency_injector.wiring import Provide
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
import time
import random
from src.aetherflow import Node, BaseFlowContext, node


# å®šä¹‰æµ‹è¯•æ•°æ®ç»“æ„
@dataclass
class UserInput:
    name: str
    age: int

@dataclass  
class ProcessedUser:
    formatted_name: str
    is_adult: bool

@dataclass
class FinalResult:
    message: str
    user_type: str


def test_basic_then():
    """æµ‹è¯•åŸºæœ¬çš„thenåŠŸèƒ½"""
    print("=== æµ‹è¯•åŸºæœ¬thenåŠŸèƒ½ ===")
    
    def process_user_input(user: UserInput) -> ProcessedUser:
        print(f"Processing: {user.name}, age: {user.age}")
        return ProcessedUser(
            formatted_name=user.name.title(),
            is_adult=user.age >= 18
        )
    
    def generate_final_result(processed: ProcessedUser) -> FinalResult:
        print(f"Generating result for: {processed.formatted_name}")
        user_type = "æˆäºº" if processed.is_adult else "æœªæˆå¹´"
        return FinalResult(
            message=f"æ¬¢è¿ {processed.formatted_name}",
            user_type=user_type
        )
    
    # åˆ›å»ºèŠ‚ç‚¹
    node1 = Node(process_user_input, name="process_user")
    node2 = Node(generate_final_result, name="generate_result")
    
    print(f"Node1: {node1}")
    print(f"Node2: {node2}")
    
    # æµ‹è¯•thenç»„åˆ
    pipeline = node1.then(node2)
    print(f"Pipeline: {pipeline}")
    
    # æ‰§è¡Œæµ‹è¯•
    user_input = UserInput(name="alice", age=25)
    result = pipeline(user_input)
    
    print(f"Pipeline result: {result}")
    assert result.message == "æ¬¢è¿ Alice"
    assert result.user_type == "æˆäºº"
    print("âœ… åŸºæœ¬thenæµ‹è¯•é€šè¿‡")


def test_chain_then():
    """æµ‹è¯•é“¾å¼thenè°ƒç”¨"""
    print("\n=== æµ‹è¯•é“¾å¼thenè°ƒç”¨ ===")
    
    def multiply_by_2(x: int) -> int:
        result = x * 2
        print(f"Multiply: {x} -> {result}")
        return result
        
    def add_10(x: int) -> int:
        result = x + 10
        print(f"Add 10: {x} -> {result}")
        return result
        
    def format_result(x: int) -> str:
        result = f"final_{x}"
        print(f"Format: {x} -> {result}")
        return result
    
    # åˆ›å»ºèŠ‚ç‚¹
    step1 = Node(multiply_by_2, name="multiply")
    step2 = Node(add_10, name="add")
    step3 = Node(format_result, name="format")
    
    # ä¸‰çº§é“¾å¼è°ƒç”¨
    pipeline = step1.then(step2).then(step3)
    print(f"Chain pipeline: {pipeline}")
    
    # æ‰§è¡Œ: 5 -> 10 -> 20 -> "final_20"
    result = pipeline(5)
    print(f"Chain result: {result}")
    assert result == "final_20"
    print("âœ… é“¾å¼thenæµ‹è¯•é€šè¿‡")


def test_then_with_dependency_injection():
    """æµ‹è¯•thené“¾å¼è°ƒç”¨ä¸­çš„ä¾èµ–æ³¨å…¥"""
    print("\n=== æµ‹è¯•then + ä¾èµ–æ³¨å…¥ ===")
    
    # ç¬¬ä¸€ä¸ªèŠ‚ç‚¹ï¼šå¤„ç†è¾“å…¥å¹¶å­˜å‚¨åˆ°state
    def process_input(data: dict, context: BaseFlowContext = Provide[BaseFlowContext]) -> dict:
        state = context.state()
        processed_value = data['input'] * 2
        state['step1_processed'] = processed_value
        state['step1_timestamp'] = '2024-01-01'
        print(f"Step1: {data['input']} -> {processed_value} (stored in state)")
        return {'processed': processed_value, 'original': data['input']}
    
    # ç¬¬äºŒä¸ªèŠ‚ç‚¹ï¼šä»stateè¯»å–å¹¶è¿›ä¸€æ­¥å¤„ç†
    def enhance_data(data: dict, context: BaseFlowContext = Provide[BaseFlowContext]) -> dict:
        state = context.state()
        # è¯»å–å‰ä¸€æ­¥çš„state
        step1_value = state.get('step1_processed', 0)
        enhanced = step1_value + data['processed'] + 10
        state['step2_enhanced'] = enhanced
        state['step2_source'] = f"from_step1_{step1_value}"
        print(f"Step2: enhanced {enhanced} using state value {step1_value}")
        return {'enhanced': enhanced, 'chain_data': data}
    
    # ç¬¬ä¸‰ä¸ªèŠ‚ç‚¹ï¼šæœ€ç»ˆæ±‡æ€»
    def finalize_result(data: dict, context: BaseFlowContext = Provide[BaseFlowContext]) -> dict:
        state = context.state()
        final_value = data['enhanced'] * 1.5
        state['final_result'] = final_value
        state['processing_chain'] = [
            state.get('step1_processed'),
            state.get('step2_enhanced'), 
            final_value
        ]
        print(f"Step3: final result {final_value}")
        return {
            'final': final_value,
            'chain_history': state['processing_chain'],
            'metadata': {
                'step1_time': state.get('step1_timestamp'),
                'step2_source': state.get('step2_source')
            }
        }
    
    # åˆ›å»ºèŠ‚ç‚¹
    node1 = Node(process_input, name="process")
    node2 = Node(enhance_data, name="enhance") 
    node3 = Node(finalize_result, name="finalize")
    
    # åˆ›å»ºå¹¶é…ç½®container
    container = BaseFlowContext()
    container.wire(modules=[__name__])
    
    # æ„å»ºé“¾å¼è°ƒç”¨
    pipeline = node1.then(node2).then(node3)
    print(f"Injection pipeline: {pipeline}")
    
    # æ‰§è¡Œé“¾å¼è°ƒç”¨
    result = pipeline({'input': 5})
    
    print(f"é“¾å¼è°ƒç”¨ç»“æœ: {result}")
    print(f"æœ€ç»ˆstate: {container.state()}")
    
    # éªŒè¯é“¾å¼è°ƒç”¨ç»“æœ - ((5*2) + (5*2) + 10) * 1.5 = 30 * 1.5 = 45
    assert result['final'] == 45.0
    assert result['chain_history'] == [10, 30, 45.0]
    assert result['metadata']['step1_time'] == '2024-01-01'
    assert result['metadata']['step2_source'] == 'from_step1_10'
    
    # éªŒè¯stateä¸­çš„ä¸­é—´ç»“æœ
    final_state = container.state()
    assert final_state['step1_processed'] == 10
    assert final_state['step2_enhanced'] == 30
    assert final_state['final_result'] == 45.0
    print("âœ… then + ä¾èµ–æ³¨å…¥æµ‹è¯•é€šè¿‡")


def test_decorator_with_then_chain():
    """æµ‹è¯•@nodeè£…é¥°å™¨ä¸thené“¾å¼è°ƒç”¨çš„ç»“åˆ"""
    print("\n=== æµ‹è¯•@nodeè£…é¥°å™¨ + thené“¾å¼è°ƒç”¨ ===")
    
    @node
    def extract_number(text: str, context: BaseFlowContext = Provide[BaseFlowContext]) -> int:
        state = context.state()
        # æå–æ–‡æœ¬ä¸­çš„æ•°å­—
        numbers = ''.join(filter(str.isdigit, text))
        extracted = int(numbers) if numbers else 0
        state['extracted_number'] = extracted
        state['original_text'] = text
        print(f"Extracted {extracted} from '{text}'")
        return extracted
    
    @node
    def calculate_square(num: int, context: BaseFlowContext = Provide[BaseFlowContext]) -> int:
        state = context.state()
        squared = num * num
        state['squared_result'] = squared
        print(f"Squared {num} to get {squared}")
        return squared
    
    @node
    def format_output(num: int, context: BaseFlowContext = Provide[BaseFlowContext]) -> dict:
        state = context.state()
        original_text = state.get('original_text', 'unknown')
        extracted = state.get('extracted_number', 0)
        
        result = {
            'final_result': num,
            'calculation_chain': f"{original_text} -> {extracted} -> {num}",
            'operation': 'extract_and_square'
        }
        state['final_output'] = result
        print(f"Formatted final output: {result}")
        return result
    
    # é…ç½®ä¾èµ–æ³¨å…¥
    container = BaseFlowContext()
    container.wire(modules=[__name__])
    
    # æ„å»ºè£…é¥°å™¨èŠ‚ç‚¹çš„é“¾å¼è°ƒç”¨
    pipeline = extract_number.then(calculate_square).then(format_output)
    
    # æ‰§è¡Œ: "hello123world" -> 123 -> 15129 -> formatted result
    result = pipeline("hello123world")
    
    print(f"è£…é¥°å™¨é“¾å¼ç»“æœ: {result}")
    print(f"è£…é¥°å™¨é“¾å¼state: {container.state()}")
    
    assert result['final_result'] == 15129  # 123^2 = 15129
    assert result['calculation_chain'] == "hello123world -> 123 -> 15129"
    assert container.state()['extracted_number'] == 123
    assert container.state()['squared_result'] == 15129
    print("âœ… @nodeè£…é¥°å™¨ + thené“¾å¼è°ƒç”¨æµ‹è¯•é€šè¿‡")


def test_mixed_injection_and_simple_nodes():
    """æµ‹è¯•æ··åˆä½¿ç”¨æœ‰æ³¨å…¥å’Œæ— æ³¨å…¥çš„èŠ‚ç‚¹"""
    print("\n=== æµ‹è¯•æ··åˆèŠ‚ç‚¹ç±»å‹ ===")
    
    # ç®€å•èŠ‚ç‚¹ï¼ˆæ— æ³¨å…¥ï¼‰
    def simple_double(x: int) -> int:
        result = x * 2
        print(f"Simple double: {x} -> {result}")
        return result
    
    # ä¾èµ–æ³¨å…¥èŠ‚ç‚¹
    def state_tracker(x: int, context: BaseFlowContext = Provide[BaseFlowContext]) -> int:
        state = context.state()
        state['current_value'] = x
        state['operations'] = state.get('operations', []) + ['tracked']
        print(f"State tracker: {x} (operations: {state['operations']})")
        return x + 5
    
    # å¦ä¸€ä¸ªç®€å•èŠ‚ç‚¹
    def simple_format(x: int) -> str:
        result = f"result_{x}"
        print(f"Simple format: {x} -> {result}")
        return result
    
    # åˆ›å»ºèŠ‚ç‚¹
    double_node = Node(simple_double, name="double")
    track_node = Node(state_tracker, name="tracker") 
    format_node = Node(simple_format, name="format")
    
    # é…ç½®å®¹å™¨ï¼ˆåªå¯¹éœ€è¦æ³¨å…¥çš„èŠ‚ç‚¹ç”Ÿæ•ˆï¼‰
    container = BaseFlowContext()
    container.wire(modules=[__name__])
    
    # æ··åˆé“¾å¼è°ƒç”¨ï¼šsimple -> injection -> simple
    mixed_pipeline = double_node.then(track_node).then(format_node)
    
    # æ‰§è¡Œ: 10 -> 20 -> 25 -> "result_25"
    result = mixed_pipeline(10)
    
    print(f"æ··åˆèŠ‚ç‚¹ç»“æœ: {result}")
    print(f"æ··åˆèŠ‚ç‚¹state: {container.state()}")
    
    assert result == "result_25"
    assert container.state()['current_value'] == 20  # doubleåçš„å€¼
    assert container.state()['operations'] == ['tracked']
    print("âœ… æ··åˆèŠ‚ç‚¹ç±»å‹æµ‹è¯•é€šè¿‡")


def test_type_validation_in_chains():
    """æµ‹è¯•é“¾å¼è°ƒç”¨ä¸­çš„ç±»å‹éªŒè¯"""
    print("\n=== æµ‹è¯•é“¾å¼è°ƒç”¨ç±»å‹éªŒè¯ ===")
    
    def strict_int_processor(x: int) -> str:
        return f"processed_{x}"
    
    def strict_str_processor(s: str) -> int:
        return len(s)
    
    def strict_final_processor(x: int) -> dict:
        return {'length': x, 'valid': x > 5}
    
    node1 = Node(strict_int_processor, name="int_to_str")
    node2 = Node(strict_str_processor, name="str_to_int")
    node3 = Node(strict_final_processor, name="final_check")
    
    pipeline = node1.then(node2).then(node3)
    
    # æ­£ç¡®çš„ç±»å‹è¾“å…¥
    result = pipeline(42)
    print(f"Valid chain result: {result}")
    assert result['length'] == 12  # len("processed_42") = 12
    assert result['valid'] == True  # 12 > 5
    
    # æµ‹è¯•ç±»å‹é”™è¯¯ï¼ˆåº”è¯¥è¢«Pydanticæ•è·ï¼‰
    try:
        pipeline("invalid")  # ä¼ é€’å­—ç¬¦ä¸²ç»™æœŸæœ›intçš„å‡½æ•°
        assert False, "åº”è¯¥æŠ›å‡ºéªŒè¯é”™è¯¯"
    except Exception as e:
        print(f"Expected validation error: {type(e).__name__}")
        print("âœ… é“¾å¼è°ƒç”¨ç±»å‹éªŒè¯æµ‹è¯•é€šè¿‡")


def test_user_input_parameter_validation():
    """æµ‹è¯•ç”¨æˆ·ä¼ å…¥å‚æ•°çš„ç±»å‹æ ¡éªŒ"""
    print("\n=== æµ‹è¯•ç”¨æˆ·ä¼ å…¥å‚æ•°æ ¡éªŒ ===")
    
    # ä¸¥æ ¼çš„æ•´æ•°è¾“å…¥èŠ‚ç‚¹
    def strict_int_input(num: int) -> str:
        print(f"å¤„ç†æ•´æ•°è¾“å…¥: {num}")
        return f"number_{num}"
    
    # ä¸¥æ ¼çš„å­—å…¸è¾“å…¥èŠ‚ç‚¹  
    from typing import Dict
    def strict_dict_input(data: Dict[str, int]) -> int:
        print(f"å¤„ç†å­—å…¸è¾“å…¥: {data}")
        return sum(data.values())
    
    # å¤æ‚ç±»å‹è¾“å…¥èŠ‚ç‚¹
    from typing import List, Tuple
    def complex_input(items: List[Tuple[str, int]]) -> Dict[str, int]:
        print(f"å¤„ç†å¤æ‚è¾“å…¥: {items}")
        return {name: value * 2 for name, value in items}
    
    # æµ‹è¯•1: æ­£ç¡®çš„æ•´æ•°è¾“å…¥
    int_node = Node(strict_int_input, name="int_input")
    result1 = int_node(42)
    print(f"æ­£ç¡®æ•´æ•°è¾“å…¥ç»“æœ: {result1}")
    assert result1 == "number_42"
    
    # æµ‹è¯•2: é”™è¯¯çš„æ•´æ•°è¾“å…¥ç±»å‹
    try:
        int_node("not_a_number")  # ä¼ é€’å­—ç¬¦ä¸²ç»™æœŸæœ›intçš„å‡½æ•°
        assert False, "åº”è¯¥æŠ›å‡ºç±»å‹éªŒè¯é”™è¯¯"
    except Exception as e:
        print(f"âœ… æ­£ç¡®æ•è·é”™è¯¯æ•´æ•°è¾“å…¥: {type(e).__name__}")
    
    # æµ‹è¯•3: æ­£ç¡®çš„å­—å…¸è¾“å…¥
    dict_node = Node(strict_dict_input, name="dict_input")
    result3 = dict_node({"a": 10, "b": 20, "c": 30})
    print(f"æ­£ç¡®å­—å…¸è¾“å…¥ç»“æœ: {result3}")
    assert result3 == 60
    
    # æµ‹è¯•4: é”™è¯¯çš„å­—å…¸è¾“å…¥ç±»å‹
    try:
        dict_node({"a": "not_int", "b": 20})  # å­—å…¸å€¼ç±»å‹é”™è¯¯
        assert False, "åº”è¯¥æŠ›å‡ºå­—å…¸å€¼ç±»å‹éªŒè¯é”™è¯¯"
    except Exception as e:
        print(f"âœ… æ­£ç¡®æ•è·é”™è¯¯å­—å…¸è¾“å…¥: {type(e).__name__}")
    
    # æµ‹è¯•5: å¤æ‚ç±»å‹è¾“å…¥
    complex_node = Node(complex_input, name="complex_input")
    result5 = complex_node([("apple", 5), ("banana", 3)])
    print(f"å¤æ‚ç±»å‹è¾“å…¥ç»“æœ: {result5}")
    assert result5 == {"apple": 10, "banana": 6}
    
    # æµ‹è¯•6: é”™è¯¯çš„å¤æ‚ç±»å‹è¾“å…¥
    try:
        complex_node([("apple", "not_int"), ("banana", 3)])  # tupleä¸­ç±»å‹é”™è¯¯
        assert False, "åº”è¯¥æŠ›å‡ºå¤æ‚ç±»å‹éªŒè¯é”™è¯¯"
    except Exception as e:
        print(f"âœ… æ­£ç¡®æ•è·é”™è¯¯å¤æ‚ç±»å‹è¾“å…¥: {type(e).__name__}")
    
    print("âœ… ç”¨æˆ·ä¼ å…¥å‚æ•°æ ¡éªŒæµ‹è¯•é€šè¿‡")


def test_node_output_to_input_validation():
    """æµ‹è¯•èŠ‚ç‚¹é—´è¾“å‡ºåˆ°è¾“å…¥çš„å‚æ•°ç±»å‹æ ¡éªŒ"""
    print("\n=== æµ‹è¯•èŠ‚ç‚¹é—´å‚æ•°ä¼ é€’æ ¡éªŒ ===")
    
    # å®šä¹‰ä¸€ç³»åˆ—æœ‰æ˜ç¡®è¾“å…¥è¾“å‡ºç±»å‹çš„èŠ‚ç‚¹
    def int_to_str_node(num: int) -> str:
        result = f"str_{num}"
        print(f"int->str: {num} -> {result}")
        return result
    
    def str_to_list_node(text: str) -> List[str]:
        result = text.split("_")
        print(f"str->list: {text} -> {result}")
        return result
    
    def list_to_dict_node(items: List[str]) -> Dict[str, int]:
        result = {item: len(item) for item in items}
        print(f"list->dict: {items} -> {result}")
        return result
    
    def dict_to_int_node(data: Dict[str, int]) -> int:
        result = sum(data.values())
        print(f"dict->int: {data} -> {result}")
        return result
    
    # æ•…æ„è¿”å›é”™è¯¯ç±»å‹çš„èŠ‚ç‚¹
    def wrong_output_type(num: int) -> str:
        print(f"è¿”å›é”™è¯¯ç±»å‹: {num}")
        return num * 2  # å£°æ˜è¿”å›strä½†å®é™…è¿”å›int
    
    def expect_str_input(text: str) -> str:
        print(f"æœŸæœ›å­—ç¬¦ä¸²è¾“å…¥: {text}")
        return text.upper()
    
    # æµ‹è¯•1: æ­£ç¡®çš„ç±»å‹é“¾å¼ä¼ é€’
    node1 = Node(int_to_str_node, name="int_to_str")
    node2 = Node(str_to_list_node, name="str_to_list")  
    node3 = Node(list_to_dict_node, name="list_to_dict")
    node4 = Node(dict_to_int_node, name="dict_to_int")
    
    correct_pipeline = node1.then(node2).then(node3).then(node4)
    result1 = correct_pipeline(123)  # 123 -> "str_123" -> ["str", "123"] -> {"str":3, "123":3} -> 6
    print(f"æ­£ç¡®ç±»å‹é“¾å¼ç»“æœ: {result1}")
    assert result1 == 6  # len("str") + len("123") = 3 + 3 = 6
    
    # æµ‹è¯•2: ä¸­é—´èŠ‚ç‚¹è¿”å›é”™è¯¯ç±»å‹
    wrong_node1 = Node(wrong_output_type, name="wrong_output")
    correct_node2 = Node(expect_str_input, name="expect_str")
    
    try:
        # è¿™ä¸ªé“¾å¼è°ƒç”¨åº”è¯¥å¤±è´¥ï¼Œå› ä¸ºwrong_output_typeè¿”å›intä½†ä¸‹ä¸€ä¸ªèŠ‚ç‚¹æœŸæœ›str
        wrong_pipeline = wrong_node1.then(correct_node2)
        result2 = wrong_pipeline(10)
        print(f"âš ï¸  é”™è¯¯ç±»å‹ä¼ é€’æœªè¢«æ•è·: {result2}")
        # å¦‚æœPydanticè‡ªåŠ¨è½¬æ¢äº†ç±»å‹ï¼ŒéªŒè¯è½¬æ¢æ˜¯å¦æ­£ç¡®
        assert isinstance(result2, str), "åº”è¯¥è½¬æ¢ä¸ºå­—ç¬¦ä¸²ç±»å‹"
    except Exception as e:
        print(f"âœ… æ­£ç¡®æ•è·èŠ‚ç‚¹é—´ç±»å‹ä¸åŒ¹é…: {type(e).__name__}")
    
    # æµ‹è¯•3: å¤æ‚çš„ç±»å‹ä¸åŒ¹é…åœºæ™¯
    from typing import Optional
    def optional_input_node(data: Optional[Dict[str, int]]) -> str:
        if data is None:
            return "empty"
        return f"data_count_{len(data)}"
    
    def return_none_node(x: int) -> None:
        print(f"è¿”å›None: {x}")
        return None
    
    def return_optional_dict(x: int) -> Optional[Dict[str, int]]:
        if x > 0:
            return {"value": x}
        return None
    
    # æµ‹è¯•Noneä¼ é€’
    none_node = Node(return_none_node, name="return_none")
    optional_node = Node(optional_input_node, name="optional_input")
    
    try:
        none_pipeline = none_node.then(optional_node)
        result3 = none_pipeline(5)
        print(f"Noneä¼ é€’ç»“æœ: {result3}")
        # å¦‚æœæˆåŠŸï¼ŒéªŒè¯ç»“æœ
        assert result3 in ["empty", "NONE"], "Noneåº”è¯¥è¢«æ­£ç¡®å¤„ç†"
    except Exception as e:
        print(f"Noneä¼ é€’å¤±è´¥: {type(e).__name__}")
    
    # æµ‹è¯•Optionalç±»å‹ä¼ é€’
    optional_dict_node = Node(return_optional_dict, name="return_optional")
    optional_pipeline = optional_dict_node.then(optional_node)
    
    result4 = optional_pipeline(10)  # è¿”å›{"value": 10} -> "data_count_1"
    print(f"Optionalç±»å‹ä¼ é€’ç»“æœ: {result4}")
    assert result4 == "data_count_1"
    
    result5 = optional_pipeline(-5)  # è¿”å›None -> "empty"
    print(f"Optional Noneä¼ é€’ç»“æœ: {result5}")
    assert result5 == "empty"
    
    print("âœ… èŠ‚ç‚¹é—´å‚æ•°ä¼ é€’æ ¡éªŒæµ‹è¯•é€šè¿‡")


def test_chain_type_mismatch_errors():
    """æµ‹è¯•é“¾å¼è°ƒç”¨ä¸­çš„ç±»å‹ä¸åŒ¹é…é”™è¯¯å¤„ç†"""
    print("\n=== æµ‹è¯•é“¾å¼è°ƒç”¨ç±»å‹ä¸åŒ¹é…é”™è¯¯ ===")
    
    # åˆ›å»ºä¸€ç³»åˆ—ç±»å‹ä¸å…¼å®¹çš„èŠ‚ç‚¹
    def produce_int(x: str) -> int:
        return len(x)
    
    def expect_str(x: str) -> str:  # æœŸæœ›strä½†ä¸Šä¸ªèŠ‚ç‚¹è¿”å›int
        return x.upper()
    
    def produce_list(x: int) -> List[int]:
        return [x, x*2, x*3]
    
    def expect_dict(x: Dict[str, int]) -> int:  # æœŸæœ›dictä½†ä¸Šä¸ªèŠ‚ç‚¹è¿”å›list
        return sum(x.values())
    
    # æµ‹è¯•1: int->str ç±»å‹ä¸åŒ¹é…
    int_node = Node(produce_int, name="produce_int")
    str_node = Node(expect_str, name="expect_str")
    
    try:
        type_mismatch_1 = int_node.then(str_node)
        result1 = type_mismatch_1("hello")  # "hello" -> 5 -> expect_str(5) åº”è¯¥å¤±è´¥
        print(f"âš ï¸  int->strä¸åŒ¹é…æœªæ•è·: {result1}")
        # å¯èƒ½Pydanticè‡ªåŠ¨è½¬æ¢äº†
        assert isinstance(result1, str), "åº”è¯¥è½¬æ¢ä¸ºå­—ç¬¦ä¸²"
    except Exception as e:
        print(f"âœ… æ­£ç¡®æ•è·int->strä¸åŒ¹é…: {type(e).__name__}")
    
    # æµ‹è¯•2: list->dict ç±»å‹ä¸åŒ¹é…  
    list_node = Node(produce_list, name="produce_list")
    dict_node = Node(expect_dict, name="expect_dict")
    
    try:
        type_mismatch_2 = list_node.then(dict_node)
        result2 = type_mismatch_2(3)  # 3 -> [3,6,9] -> expect_dict([3,6,9]) åº”è¯¥å¤±è´¥
        assert False, "list->dictä¸åŒ¹é…åº”è¯¥æŠ›å‡ºé”™è¯¯"
    except Exception as e:
        print(f"âœ… æ­£ç¡®æ•è·list->dictä¸åŒ¹é…: {type(e).__name__}")
    
    # æµ‹è¯•3: ä¸‰çº§é“¾å¼è°ƒç”¨ä¸­çš„ä¸­é—´ç±»å‹é”™è¯¯
    def step1_str_to_int(s: str) -> int:
        return int(s) if s.isdigit() else 0
    
    def step2_int_to_str(n: int) -> str:
        return f"result_{n}"
    
    def step3_expect_int(n: int) -> dict:  # æœŸæœ›intä½†ä¸Šä¸ªèŠ‚ç‚¹è¿”å›str
        return {"doubled": n * 2}
    
    step1 = Node(step1_str_to_int, name="step1")
    step2 = Node(step2_int_to_str, name="step2") 
    step3 = Node(step3_expect_int, name="step3")
    
    try:
        three_step_chain = step1.then(step2).then(step3)
        result3 = three_step_chain("42")  # "42" -> 42 -> "result_42" -> step3("result_42") åº”è¯¥å¤±è´¥
        assert False, "ä¸‰çº§é“¾å¼ç±»å‹ä¸åŒ¹é…åº”è¯¥æŠ›å‡ºé”™è¯¯"
    except Exception as e:
        print(f"âœ… æ­£ç¡®æ•è·ä¸‰çº§é“¾å¼ç±»å‹ä¸åŒ¹é…: {type(e).__name__}")
    
    # æµ‹è¯•4: æ··åˆä¾èµ–æ³¨å…¥å’Œç±»å‹ä¸åŒ¹é…
    def inject_and_wrong_type(data: str, context: BaseFlowContext = Provide[BaseFlowContext]) -> int:
        state = context.state()
        state['input_data'] = data
        return len(data)  # è¿”å›int
    
    def expect_str_with_injection(text: str, context: BaseFlowContext = Provide[BaseFlowContext]) -> str:
        state = context.state()
        state['processed_text'] = text
        return text.upper()  # æœŸæœ›strè¾“å…¥
    
    # é…ç½®å®¹å™¨
    container = BaseFlowContext()
    container.wire(modules=[__name__])
    
    inject_wrong_node = Node(inject_and_wrong_type, name="inject_wrong")
    expect_str_inject_node = Node(expect_str_with_injection, name="expect_str_inject")
    
    try:
        inject_mismatch_chain = inject_wrong_node.then(expect_str_inject_node)
        result4 = inject_mismatch_chain("test")  # "test" -> 4 -> expect_str_with_injection(4) 
        print(f"âš ï¸  æ³¨å…¥+ç±»å‹ä¸åŒ¹é…æœªæ•è·: {result4}")
    except Exception as e:
        print(f"âœ… æ­£ç¡®æ•è·æ³¨å…¥+ç±»å‹ä¸åŒ¹é…: {type(e).__name__}")
    
    print("âœ… é“¾å¼è°ƒç”¨ç±»å‹ä¸åŒ¹é…é”™è¯¯æµ‹è¯•å®Œæˆ")


def test_pydantic_model_passing():
    """æµ‹è¯•èŠ‚ç‚¹ä¹‹é—´ä¼ é€’Pydanticæ¨¡å‹"""
    print("\n=== æµ‹è¯•Pydanticæ¨¡å‹ä¼ é€’ ===")
    
    # å®šä¹‰Pydanticæ¨¡å‹
    class UserModel(BaseModel):
        name: str = Field(..., min_length=1, max_length=50)
        age: int = Field(..., ge=0, le=150)
        email: str = Field(..., pattern=r'^[\w\.-]+@[\w\.-]+\.\w+$')
        
        @validator('name')
        def name_must_be_alpha(cls, v):
            if not v.replace(' ', '').isalpha():
                raise ValueError('åå­—å¿…é¡»åªåŒ…å«å­—æ¯å’Œç©ºæ ¼')
            return v.title()
    
    class ProcessedUserModel(BaseModel):
        id: int
        full_name: str
        is_adult: bool
        email_domain: str
        created_at: str
        
    class UserStatsModel(BaseModel):
        user_count: int
        adult_count: int  
        domains: List[str]
        average_age: float
        
    # èŠ‚ç‚¹1: è¾“å…¥éªŒè¯å’Œåˆæ­¥å¤„ç†
    def validate_and_process_user(user_data: dict) -> UserModel:
        print(f"éªŒè¯ç”¨æˆ·æ•°æ®: {user_data}")
        # Pydanticè‡ªåŠ¨éªŒè¯å’Œè½¬æ¢
        user = UserModel(**user_data)
        print(f"éªŒè¯é€šè¿‡çš„ç”¨æˆ·: {user}")
        return user
    
    # èŠ‚ç‚¹2: ç”¨æˆ·æ¨¡å‹è½¬æ¢
    def transform_user_model(user: UserModel) -> ProcessedUserModel:
        print(f"è½¬æ¢ç”¨æˆ·æ¨¡å‹: {user.name}, {user.age}")
        processed = ProcessedUserModel(
            id=hash(user.email) % 10000,  # ç®€å•çš„IDç”Ÿæˆ
            full_name=user.name,
            is_adult=user.age >= 18,
            email_domain=user.email.split('@')[1],
            created_at='2024-01-01T00:00:00Z'
        )
        print(f"è½¬æ¢åçš„ç”¨æˆ·: {processed}")
        return processed
        
    # èŠ‚ç‚¹3: èšåˆç»Ÿè®¡ï¼ˆæ¨¡æ‹Ÿæ‰¹å¤„ç†ï¼‰
    def aggregate_user_stats(processed_user: ProcessedUserModel, 
                           context: BaseFlowContext = Provide[BaseFlowContext]) -> UserStatsModel:
        state = context.state()
        
        # ä»çŠ¶æ€ä¸­è·å–ç´¯ç§¯æ•°æ®
        users = state.get('processed_users', [])
        users.append(processed_user)
        state['processed_users'] = users
        
        print(f"èšåˆç»Ÿè®¡ï¼Œå½“å‰ç”¨æˆ·æ•°: {len(users)}")
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        adult_count = sum(1 for u in users if u.is_adult)
        domains = list(set(u.email_domain for u in users))
        # è¿™é‡Œéœ€è¦ä»åŸå§‹æ•°æ®è®¡ç®—å¹³å‡å¹´é¾„ï¼Œç®€åŒ–å¤„ç†
        avg_age = 25.0  # æ¨¡æ‹Ÿå¹³å‡å¹´é¾„
        
        stats = UserStatsModel(
            user_count=len(users),
            adult_count=adult_count,
            domains=domains,
            average_age=avg_age
        )
        print(f"ç»Ÿè®¡ç»“æœ: {stats}")
        return stats
    
    # åˆ›å»ºèŠ‚ç‚¹
    validate_node = Node(validate_and_process_user, name="validate")
    transform_node = Node(transform_user_model, name="transform")
    aggregate_node = Node(aggregate_user_stats, name="aggregate")
    
    # é…ç½®å®¹å™¨
    container = BaseFlowContext()
    container.wire(modules=[__name__])
    
    # æ„å»ºé“¾å¼è°ƒç”¨
    pipeline = validate_node.then(transform_node).then(aggregate_node)
    
    # æµ‹è¯•1: æ­£ç¡®çš„ç”¨æˆ·æ•°æ®
    user_data1 = {
        "name": "alice smith",
        "age": 25,
        "email": "alice@example.com"
    }
    
    result1 = pipeline(user_data1)
    print(f"ç¬¬ä¸€ä¸ªç”¨æˆ·å¤„ç†ç»“æœ: {result1}")
    
    assert isinstance(result1, UserStatsModel)
    assert result1.user_count == 1
    assert result1.adult_count == 1
    assert "example.com" in result1.domains
    
    # æµ‹è¯•2: ç¬¬äºŒä¸ªç”¨æˆ·ï¼ˆç´¯ç§¯ï¼‰
    user_data2 = {
        "name": "bob jones", 
        "age": 17,
        "email": "bob@test.org"
    }
    
    result2 = pipeline(user_data2)
    print(f"ç¬¬äºŒä¸ªç”¨æˆ·å¤„ç†ç»“æœ: {result2}")
    
    assert result2.user_count == 2
    assert result2.adult_count == 1  # åªæœ‰aliceæ˜¯æˆå¹´äºº
    assert len(result2.domains) == 2  # example.com å’Œ test.org
    
    # æµ‹è¯•3: æ— æ•ˆçš„ç”¨æˆ·æ•°æ®ï¼ˆåº”è¯¥è¢«Pydanticæ•è·ï¼‰
    try:
        invalid_data = {
            "name": "123invalid",  # åŒ…å«æ•°å­—ï¼Œä¸ç¬¦åˆvalidator
            "age": 200,  # è¶…å‡ºèŒƒå›´
            "email": "invalid-email"  # æ— æ•ˆé‚®ç®±æ ¼å¼
        }
        pipeline(invalid_data)
        assert False, "åº”è¯¥æŠ›å‡ºPydanticéªŒè¯é”™è¯¯"
    except Exception as e:
        print(f"âœ… æ­£ç¡®æ•è·PydanticéªŒè¯é”™è¯¯: {type(e).__name__}")
    
    print("âœ… Pydanticæ¨¡å‹ä¼ é€’æµ‹è¯•é€šè¿‡")


def test_complex_pydantic_model_chains():
    """æµ‹è¯•å¤æ‚çš„Pydanticæ¨¡å‹é“¾å¼ä¼ é€’"""
    print("\n=== æµ‹è¯•å¤æ‚Pydanticæ¨¡å‹é“¾å¼ä¼ é€’ ===")
    
    # å®šä¹‰å¤æ‚çš„åµŒå¥—æ¨¡å‹
    class AddressModel(BaseModel):
        street: str
        city: str
        country: str
        postal_code: str = Field(..., pattern=r'^\d{5}(-\d{4})?$')
        
    class CompanyModel(BaseModel):
        name: str
        industry: str
        employees: int = Field(..., gt=0)
        
    class PersonModel(BaseModel):
        name: str
        age: int = Field(..., ge=18)
        address: AddressModel
        company: Optional[CompanyModel] = None
        skills: List[str] = Field(default_factory=list)
        
    class EnrichedPersonModel(BaseModel):
        person: PersonModel
        location_score: float = Field(..., ge=0.0, le=10.0)
        career_level: str
        skill_categories: Dict[str, List[str]]
        
    class AnalyticsModel(BaseModel):
        total_people: int
        average_age: float
        top_cities: List[str]
        skill_frequency: Dict[str, int]
        company_industries: Dict[str, int]
        
    # èŠ‚ç‚¹1: ä¸ªäººä¿¡æ¯ä¸°å¯ŒåŒ–
    def enrich_person_data(person: PersonModel) -> EnrichedPersonModel:
        print(f"ä¸°å¯ŒåŒ–ä¸ªäººæ•°æ®: {person.name}")
        
        # è®¡ç®—ä½ç½®è¯„åˆ†ï¼ˆæ¨¡æ‹Ÿï¼‰
        location_scores = {"New York": 9.0, "San Francisco": 8.5, "Austin": 7.0}
        location_score = location_scores.get(person.address.city, 5.0)
        
        # ç¡®å®šèŒä¸šçº§åˆ«
        if person.company and person.company.employees > 1000:
            career_level = "Senior"
        elif person.age >= 30:
            career_level = "Mid-level"
        else:
            career_level = "Junior"
            
        # æŠ€èƒ½åˆ†ç±»
        tech_skills = ["Python", "JavaScript", "React", "Django"]
        business_skills = ["Management", "Marketing", "Sales"]
        
        skill_categories = {
            "technical": [s for s in person.skills if s in tech_skills],
            "business": [s for s in person.skills if s in business_skills],
            "other": [s for s in person.skills if s not in tech_skills + business_skills]
        }
        
        enriched = EnrichedPersonModel(
            person=person,
            location_score=location_score,
            career_level=career_level,
            skill_categories=skill_categories
        )
        
        print(f"ä¸°å¯ŒåŒ–å®Œæˆ: {enriched.career_level}, ä½ç½®è¯„åˆ†: {enriched.location_score}")
        return enriched
        
    # èŠ‚ç‚¹2: æ•°æ®åˆ†æèšåˆ
    def analyze_enriched_data(enriched: EnrichedPersonModel,
                            context: BaseFlowContext = Provide[BaseFlowContext]) -> AnalyticsModel:
        state = context.state()
        
        # ç´¯ç§¯æ•°æ®
        people = state.get('enriched_people', [])
        people.append(enriched)
        state['enriched_people'] = people
        
        print(f"åˆ†ææ•°æ®ï¼Œå½“å‰äººæ•°: {len(people)}")
        
        # è®¡ç®—åˆ†ææŒ‡æ ‡
        total_people = len(people)
        average_age = sum(p.person.age for p in people) / total_people
        
        # ç»Ÿè®¡åŸå¸‚
        cities = [p.person.address.city for p in people]
        city_counts = {}
        for city in cities:
            city_counts[city] = city_counts.get(city, 0) + 1
        top_cities = sorted(city_counts.keys(), key=city_counts.get, reverse=True)[:3]
        
        # ç»Ÿè®¡æŠ€èƒ½
        skill_frequency = {}
        for p in people:
            for skills_list in p.skill_categories.values():
                for skill in skills_list:
                    skill_frequency[skill] = skill_frequency.get(skill, 0) + 1
        
        # ç»Ÿè®¡è¡Œä¸š
        company_industries = {}
        for p in people:
            if p.person.company:
                industry = p.person.company.industry
                company_industries[industry] = company_industries.get(industry, 0) + 1
                
        analytics = AnalyticsModel(
            total_people=total_people,
            average_age=average_age,
            top_cities=top_cities,
            skill_frequency=skill_frequency,
            company_industries=company_industries
        )
        
        print(f"åˆ†æå®Œæˆ: {analytics}")
        return analytics
    
    # åˆ›å»ºèŠ‚ç‚¹
    enrich_node = Node(enrich_person_data, name="enrich")
    analyze_node = Node(analyze_enriched_data, name="analyze")
    
    # é…ç½®å®¹å™¨
    container = BaseFlowContext()
    container.wire(modules=[__name__])
    
    # æ„å»ºé“¾å¼è°ƒç”¨
    complex_pipeline = enrich_node.then(analyze_node)
    
    # æµ‹è¯•å¤æ‚åµŒå¥—æ¨¡å‹
    person_data = {
        "name": "John Developer",
        "age": 28,
        "address": {
            "street": "123 Main St",
            "city": "San Francisco", 
            "country": "USA",
            "postal_code": "94102"
        },
        "company": {
            "name": "Tech Corp",
            "industry": "Technology",
            "employees": 5000
        },
        "skills": ["Python", "React", "Management", "Writing"]
    }
    
    result = complex_pipeline(person_data)
    
    print(f"å¤æ‚æ¨¡å‹å¤„ç†ç»“æœ: {result}")
    
    # éªŒè¯ç»“æœ
    assert isinstance(result, AnalyticsModel)
    assert result.total_people == 1
    assert result.average_age == 28.0
    assert "San Francisco" in result.top_cities
    assert result.skill_frequency["Python"] == 1
    assert result.company_industries["Technology"] == 1
    
    # æµ‹è¯•æ¨¡å‹éªŒè¯å¤±è´¥
    try:
        invalid_person = {
            "name": "Invalid Person",
            "age": 17,  # å°äº18ï¼Œä¸ç¬¦åˆçº¦æŸ
            "address": {
                "street": "123 Main St",
                "city": "Invalid",
                "country": "USA", 
                "postal_code": "invalid"  # ä¸ç¬¦åˆæ­£åˆ™è¡¨è¾¾å¼
            }
        }
        complex_pipeline(invalid_person)
        assert False, "åº”è¯¥æŠ›å‡ºå¤æ‚æ¨¡å‹éªŒè¯é”™è¯¯"
    except Exception as e:
        print(f"âœ… æ­£ç¡®æ•è·å¤æ‚æ¨¡å‹éªŒè¯é”™è¯¯: {type(e).__name__}")
    
    print("âœ… å¤æ‚Pydanticæ¨¡å‹é“¾å¼ä¼ é€’æµ‹è¯•é€šè¿‡")


def test_multithreading_state_isolation():
    """æµ‹è¯•å¤šçº¿ç¨‹ç¯å¢ƒä¸‹Nodeçš„stateå’Œcontextéš”ç¦»æ€§"""
    print("\n=== æµ‹è¯•å¤šçº¿ç¨‹Stateéš”ç¦»æ€§ ===")
    
    # ç”¨äºæ”¶é›†çº¿ç¨‹æ‰§è¡Œç»“æœçš„å­—å…¸
    thread_results = {}
    thread_states = {}
    shared_results = {}
    
    def thread_local_state_node(thread_id: int, value: int, 
                              context: BaseFlowContext = Provide[BaseFlowContext]) -> dict:
        """æµ‹è¯•çº¿ç¨‹æœ¬åœ°stateçš„èŠ‚ç‚¹"""
        state = context.state()
        shared_data = context.shared_data()
        
        # åœ¨stateä¸­å­˜å‚¨çº¿ç¨‹ç‰¹å®šçš„æ•°æ®
        state['thread_id'] = thread_id
        state['local_value'] = value
        state['processing_time'] = time.time()
        state['operations'] = state.get('operations', []) + [f'op_{thread_id}']
        
        # åœ¨shared_dataä¸­ç´¯ç§¯å…¨å±€æ•°æ®ï¼ˆæ‰€æœ‰çº¿ç¨‹å…±äº«ï¼‰
        total_processed = shared_data.get('total_processed', 0) + 1
        shared_data['total_processed'] = total_processed
        shared_data[f'thread_{thread_id}_value'] = value
        
        # æ¨¡æ‹Ÿä¸€äº›å¤„ç†æ—¶é—´
        time.sleep(random.uniform(0.001, 0.01))
        
        result = {
            'thread_id': thread_id,
            'local_state_value': state['local_value'],
            'total_operations': len(state['operations']),
            'shared_total': shared_data['total_processed']
        }
        
        print(f"çº¿ç¨‹ {thread_id}: state={dict(state)}, shared_total={shared_data['total_processed']}")
        return result
    
    def thread_processor_node(data: dict, 
                            context: BaseFlowContext = Provide[BaseFlowContext]) -> dict:
        """å¤„ç†çº¿ç¨‹æ•°æ®çš„ç¬¬äºŒä¸ªèŠ‚ç‚¹"""
        state = context.state()
        shared_data = context.shared_data()
        
        thread_id = data['thread_id']
        
        # éªŒè¯stateä¸­çš„çº¿ç¨‹æœ¬åœ°æ•°æ®ä»ç„¶å­˜åœ¨
        assert state['thread_id'] == thread_id, f"Stateæ±¡æŸ“æ£€æµ‹ï¼šæœŸæœ›thread_id={thread_id}, å®é™…={state.get('thread_id')}"
        
        # æ›´æ–°çº¿ç¨‹æœ¬åœ°çŠ¶æ€
        state['final_result'] = data['local_state_value'] * 10
        state['chain_completed'] = True
        
        # æ›´æ–°å…±äº«æ•°æ®
        if 'completed_threads' not in shared_data:
            shared_data['completed_threads'] = []
        shared_data['completed_threads'].append(thread_id)
        
        final_result = {
            'thread_id': thread_id,
            'final_value': state['final_result'],
            'state_preserved': state['thread_id'] == thread_id,
            'total_completed': len(shared_data['completed_threads']),
            'shared_data_keys': list(shared_data.keys())
        }
        
        print(f"çº¿ç¨‹ {thread_id} å®Œæˆ: final_value={state['final_result']}, å®Œæˆæ€»æ•°={len(shared_data['completed_threads'])}")
        return final_result
    
    # åˆ›å»ºèŠ‚ç‚¹å’Œæµæ°´çº¿
    state_node = Node(thread_local_state_node, name="state_node")
    processor_node = Node(thread_processor_node, name="processor_node")
    pipeline = state_node.then(processor_node)
    
    # é…ç½®ä¾èµ–æ³¨å…¥å®¹å™¨
    container = BaseFlowContext()
    container.wire(modules=[__name__])
    
    def run_thread_pipeline(thread_id: int, input_value: int):
        """åœ¨å•ç‹¬çº¿ç¨‹ä¸­è¿è¡Œpipeline"""
        try:
            result = pipeline(thread_id, input_value)
            thread_results[thread_id] = result
            
            # è·å–çº¿ç¨‹ç»“æŸæ—¶çš„stateå¿«ç…§
            state_snapshot = dict(container.state())
            thread_states[thread_id] = state_snapshot
            
        except Exception as e:
            print(f"çº¿ç¨‹ {thread_id} æ‰§è¡Œå¤±è´¥: {e}")
            thread_results[thread_id] = {'error': str(e)}
    
    # å¯åŠ¨å¤šä¸ªçº¿ç¨‹
    num_threads = 5
    test_values = [10, 20, 30, 40, 50]
    
    print(f"å¯åŠ¨ {num_threads} ä¸ªå¹¶å‘çº¿ç¨‹...")
    
    with ThreadPoolExecutor(max_workers=num_threads) as executor:
        futures = [
            executor.submit(run_thread_pipeline, i, test_values[i])
            for i in range(num_threads)
        ]
        
        # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
        for future in as_completed(futures):
            future.result()  # è·å–ç»“æœï¼Œå¦‚æœæœ‰å¼‚å¸¸ä¼šåœ¨è¿™é‡ŒæŠ›å‡º
    
    # è·å–æœ€ç»ˆçš„shared_dataçŠ¶æ€
    final_shared_data = dict(container.shared_data())
    
    print(f"\n=== çº¿ç¨‹æ‰§è¡Œç»“æœåˆ†æ ===")
    print(f"æœ€ç»ˆshared_data: {final_shared_data}")
    
    # éªŒè¯ç»“æœ
    assert len(thread_results) == num_threads, f"æœŸæœ› {num_threads} ä¸ªçº¿ç¨‹ç»“æœï¼Œå®é™…å¾—åˆ° {len(thread_results)}"
    
    # éªŒè¯Stateéš”ç¦»æ€§
    for thread_id in range(num_threads):
        result = thread_results[thread_id]
        assert 'error' not in result, f"çº¿ç¨‹ {thread_id} æ‰§è¡Œå‡ºé”™: {result.get('error')}"
        
        # éªŒè¯çº¿ç¨‹æœ¬åœ°æ•°æ®æ­£ç¡®
        assert result['thread_id'] == thread_id, f"çº¿ç¨‹IDä¸åŒ¹é…: {result['thread_id']} != {thread_id}"
        assert result['final_value'] == test_values[thread_id] * 10, f"è®¡ç®—ç»“æœé”™è¯¯: {result['final_value']}"
        assert result['state_preserved'], f"çº¿ç¨‹ {thread_id} çš„stateæ•°æ®è¢«æ±¡æŸ“"
        
        print(f"âœ… çº¿ç¨‹ {thread_id}: stateéš”ç¦»æ­£å¸¸, final_value={result['final_value']}")
    
    # éªŒè¯Shared_dataå…±äº«æ€§
    assert final_shared_data['total_processed'] == num_threads, f"å…±äº«è®¡æ•°å™¨é”™è¯¯: {final_shared_data['total_processed']}"
    assert len(final_shared_data['completed_threads']) == num_threads, f"å®Œæˆçº¿ç¨‹æ•°é”™è¯¯"
    
    # éªŒè¯æ¯ä¸ªçº¿ç¨‹çš„æ•°æ®éƒ½åœ¨shared_dataä¸­
    for thread_id in range(num_threads):
        thread_key = f'thread_{thread_id}_value'
        assert thread_key in final_shared_data, f"çº¿ç¨‹ {thread_id} æ•°æ®æœªåœ¨shared_dataä¸­æ‰¾åˆ°"
        assert final_shared_data[thread_key] == test_values[thread_id], f"çº¿ç¨‹ {thread_id} å…±äº«æ•°æ®å€¼é”™è¯¯"
    
    print(f"âœ… Shared_dataå…±äº«æ€§éªŒè¯é€šè¿‡: total_processed={final_shared_data['total_processed']}")
    print(f"âœ… ThreadLocalSingletonéš”ç¦»æ•ˆæœéªŒè¯é€šè¿‡")
    print("âœ… å¤šçº¿ç¨‹Stateéš”ç¦»æ€§æµ‹è¯•é€šè¿‡")


def test_concurrent_execution_data_consistency():
    """æµ‹è¯•shared_dataåœ¨å¤šçº¿ç¨‹ä¸­çš„å…±äº«æ€§ï¼ˆä¸æµ‹è¯•åŸå­æ“ä½œï¼‰"""
    print("\n=== æµ‹è¯•shared_dataå¤šçº¿ç¨‹å…±äº«æ€§ ===")
    
    def record_thread_data_node(thread_id: int, 
                              context: BaseFlowContext = Provide[BaseFlowContext]) -> dict:
        """å°†çº¿ç¨‹æ•°æ®è®°å½•åˆ°shared_data"""
        shared_data = context.shared_data()
        state = context.state()
        
        # è·å–å½“å‰çº¿ç¨‹å
        current_thread = threading.current_thread().name
        state['thread_name'] = current_thread
        state['thread_id'] = thread_id
        
        # è®°å½•çº¿ç¨‹ä¿¡æ¯åˆ°shared_dataï¼ˆæ¯ä¸ªçº¿ç¨‹ç”¨å”¯ä¸€keyï¼Œæ— ç«æ€æ¡ä»¶ï¼‰
        thread_key = f"thread_{thread_id}"
        shared_data[thread_key] = {
            'thread_name': current_thread,
            'thread_id': thread_id,
            'processed_at': time.time()
        }
        
        # å°†çº¿ç¨‹åŠ å…¥æ´»è·ƒçº¿ç¨‹åˆ—è¡¨ï¼ˆè¿™é‡Œå¯èƒ½æœ‰ç«æ€æ¡ä»¶ï¼Œä½†ä¸å½±å“æµ‹è¯•ç›®çš„ï¼‰
        if 'active_threads' not in shared_data:
            shared_data['active_threads'] = []
        shared_data['active_threads'].append(thread_id)
        
        return {
            'thread_name': current_thread,
            'thread_id': thread_id,
            'recorded': True
        }
    
    def verify_shared_data_node(data: dict, 
                              context: BaseFlowContext = Provide[BaseFlowContext]) -> dict:
        """éªŒè¯shared_dataä¸­çš„æ•°æ®å¯ä»¥è¢«å…¶ä»–çº¿ç¨‹è®¿é—®"""
        shared_data = context.shared_data()
        state = context.state()
        
        thread_id = data['thread_id']
        thread_key = f"thread_{thread_id}"
        
        # éªŒè¯è‡ªå·±çš„æ•°æ®ç¡®å®å­˜åœ¨äºshared_dataä¸­
        own_data_exists = thread_key in shared_data
        
        # è®°å½•éªŒè¯ç»“æœåˆ°çº¿ç¨‹æœ¬åœ°state
        state['own_data_exists'] = own_data_exists
        state['shared_data_keys'] = list(shared_data.keys())
        
        return {
            'thread_id': thread_id,
            'own_data_exists': own_data_exists,
            'total_shared_keys': len(shared_data.keys())
        }
    
    # åˆ›å»ºæµ‹è¯•pipeline
    record_node = Node(record_thread_data_node, name="record")
    verify_node = Node(verify_shared_data_node, name="verify")
    pipeline = record_node.then(verify_node)
    
    # é…ç½®å®¹å™¨
    container = BaseFlowContext()
    container.wire(modules=[__name__])
    
    # å‡†å¤‡æµ‹è¯•æ•°æ®
    num_threads = 5
    thread_ids = list(range(num_threads))
    
    concurrent_results = {}
    
    def run_concurrent_task(thread_id: int):
        """è¿è¡Œå¹¶å‘ä»»åŠ¡"""
        try:
            result = pipeline(thread_id)
            concurrent_results[thread_id] = result
        except Exception as e:
            concurrent_results[thread_id] = {'error': str(e)}
    
    print(f"å¯åŠ¨ {num_threads} ä¸ªå¹¶å‘ä»»åŠ¡æµ‹è¯•shared_dataå…±äº«æ€§")
    
    # å¯åŠ¨å¹¶å‘ä»»åŠ¡
    with ThreadPoolExecutor(max_workers=num_threads) as executor:
        futures = [
            executor.submit(run_concurrent_task, thread_id)
            for thread_id in thread_ids
        ]
        
        for future in as_completed(futures):
            future.result()
    
    # è·å–æœ€ç»ˆçŠ¶æ€
    final_shared_data = dict(container.shared_data())
    
    print(f"\n=== å¹¶å‘æ‰§è¡Œç»“æœ ===")
    print(f"shared_dataæœ€ç»ˆåŒ…å«é”®: {list(final_shared_data.keys())}")
    print(f"æ´»è·ƒçº¿ç¨‹è®°å½•: {final_shared_data.get('active_threads', [])}")
    
    # éªŒè¯shared_dataå…±äº«æ€§
    # 1. æ¯ä¸ªçº¿ç¨‹éƒ½æˆåŠŸè®°å½•äº†æ•°æ®
    for thread_id in thread_ids:
        thread_key = f"thread_{thread_id}"
        assert thread_key in final_shared_data, f"çº¿ç¨‹ {thread_id} çš„æ•°æ®æœªåœ¨shared_dataä¸­æ‰¾åˆ°"
        
        thread_data = final_shared_data[thread_key]
        assert thread_data['thread_id'] == thread_id, f"çº¿ç¨‹ {thread_id} æ•°æ®ä¸æ­£ç¡®"
    
    # 2. æ¯ä¸ªä»»åŠ¡éƒ½æˆåŠŸå®Œæˆ
    assert len(concurrent_results) == num_threads, f"ä»»åŠ¡æ•°é‡ä¸åŒ¹é…: {len(concurrent_results)} != {num_threads}"
    
    # 3. æ‰€æœ‰ä»»åŠ¡éƒ½æˆåŠŸæ‰§è¡Œä¸”éªŒè¯é€šè¿‡
    for thread_id in thread_ids:
        result = concurrent_results[thread_id]
        assert 'error' not in result, f"çº¿ç¨‹ {thread_id} æ‰§è¡Œå‡ºé”™: {result.get('error')}"
        assert result['own_data_exists'], f"çº¿ç¨‹ {thread_id} æ— æ³•åœ¨shared_dataä¸­æ‰¾åˆ°è‡ªå·±çš„æ•°æ®"
    
    # 4. éªŒè¯active_threadsåˆ—è¡¨ï¼ˆè™½ç„¶å¯èƒ½å› ç«æ€æ¡ä»¶ä¸å®Œæ•´ï¼Œä½†åº”è¯¥è‡³å°‘æœ‰æ•°æ®ï¼‰
    active_threads = final_shared_data.get('active_threads', [])
    assert len(active_threads) > 0, "active_threadsåˆ—è¡¨åº”è¯¥åŒ…å«è‡³å°‘ä¸€äº›çº¿ç¨‹ID"
    
    print(f"âœ… æ‰€æœ‰ {num_threads} ä¸ªçº¿ç¨‹éƒ½æˆåŠŸå°†æ•°æ®å†™å…¥shared_data")
    print(f"âœ… æ¯ä¸ªçº¿ç¨‹éƒ½èƒ½è®¿é—®åˆ°shared_dataä¸­çš„æ•°æ®")
    print(f"âœ… shared_dataåœ¨å¤šçº¿ç¨‹ç¯å¢ƒä¸­æ­£ç¡®å…±äº«")
    print("âœ… shared_dataå¤šçº¿ç¨‹å…±äº«æ€§æµ‹è¯•é€šè¿‡")


if __name__ == "__main__":
    print("=== Node.then() æ–¹æ³•ç»¼åˆæµ‹è¯• ===")
    
    try:
        test_basic_then()
        test_chain_then() 
        test_then_with_dependency_injection()
        test_decorator_with_then_chain()
        test_mixed_injection_and_simple_nodes()
        test_type_validation_in_chains()
        test_user_input_parameter_validation()
        test_node_output_to_input_validation()
        test_chain_type_mismatch_errors()
        test_pydantic_model_passing()
        test_complex_pydantic_model_chains()
        test_multithreading_state_isolation()
        test_concurrent_execution_data_consistency()
        print("\nğŸ‰ æ‰€æœ‰ç»¼åˆthenæ–¹æ³•æµ‹è¯•é€šè¿‡ï¼")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()