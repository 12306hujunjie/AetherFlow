#!/usr/bin/env python3
"""
å¹¶å‘å®‰å…¨æ€§æµ‹è¯•ç”¨ä¾‹

æµ‹è¯•AetherFlowæ¡†æ¶åœ¨å¤šçº¿ç¨‹å’Œå¼‚æ­¥ç¯å¢ƒä¸‹çš„æ­£ç¡®æ€§ã€‚
"""

import threading
import asyncio
import time
import concurrent.futures
from typing import Dict, Any

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from src.aetherflow import node, AppContext, BaseFlowContext


class TestConcurrentSafety:
    """å¹¶å‘å®‰å…¨æ€§æµ‹è¯•ç±»"""
    
    def test_thread_local_state_isolation(self):
        """æµ‹è¯•çº¿ç¨‹æœ¬åœ°çŠ¶æ€éš”ç¦»"""
        results = {}
        threads = []
        num_threads = 5
        
        @node
        def set_value(x):
            return {'thread_value': x + threading.current_thread().ident}
        
        @node
        def get_value(thread_value):
            return {'final_value': thread_value * 2}
        
        def worker(thread_id):
            # æ¯ä¸ªçº¿ç¨‹ä½¿ç”¨ä¸åŒçš„åˆå§‹å€¼
            initial_state = {'x': thread_id * 100}
            
            # åˆ›å»ºæµç¨‹
            flow = set_value.then(get_value)
            result = flow.run(initial_state)
            
            results[thread_id] = result
        
        # å¯åŠ¨å¤šä¸ªçº¿ç¨‹
        for i in range(num_threads):
            thread = threading.Thread(target=worker, args=(i,))
            threads.append(thread)
            thread.start()
        
        # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
        for thread in threads:
            thread.join()
        
        # éªŒè¯ç»“æœ
        assert len(results) == num_threads
        
        # æ¯ä¸ªçº¿ç¨‹çš„ç»“æœåº”è¯¥ä¸åŒä¸”æ­£ç¡®
        for thread_id, result in results.items():
            expected_thread_value = thread_id * 100 + threading.current_thread().ident
            # æ³¨æ„ï¼šç”±äºçº¿ç¨‹IDä¼šä¸åŒï¼Œæˆ‘ä»¬åªæ£€æŸ¥åŸºæœ¬é€»è¾‘
            assert 'final_value' in result
            print(f"Thread {thread_id}: {result}")
    
    def test_parallel_fan_out_thread_safety(self):
        """æµ‹è¯•å¹¶è¡Œæ‰‡å‡ºçš„çº¿ç¨‹å®‰å…¨æ€§"""
        
        @node
        def source(x):
            return x
        
        @node
        def worker_a(source):
            # æ¨¡æ‹Ÿä¸€äº›è®¡ç®—
            time.sleep(0.01)
            return source + 100
        
        @node
        def worker_b(source):
            # æ¨¡æ‹Ÿä¸€äº›è®¡ç®—
            time.sleep(0.01) 
            return source + 200
        
        @node
        def worker_c(source):
            # æ¨¡æ‹Ÿä¸€äº›è®¡ç®—
            time.sleep(0.01)
            return source + 300
        
        # æµ‹è¯•å¤šæ¬¡æ‰§è¡Œ
        for i in range(10):
            initial_state = {'x': i * 10}
            
            parallel_flow = source.fan_out_to([worker_a, worker_b, worker_c])
            result = parallel_flow.run(initial_state)
            
            # éªŒè¯æ‰€æœ‰å¹¶è¡Œç»“æœéƒ½å­˜åœ¨
            assert '__parallel_results' in result
            parallel_results = result['__parallel_results']
            
            # åº”è¯¥æœ‰3ä¸ªç»“æœ
            assert len(parallel_results) == 3
            
            # éªŒè¯ç»“æœå€¼
            expected_values = {i * 10 + 100, i * 10 + 200, i * 10 + 300}
            actual_values = set(parallel_results.values())
            assert actual_values == expected_values
            
            print(f"Iteration {i}: {parallel_results}")
    
    def test_concurrent_container_access(self):
        """æµ‹è¯•å¹¶å‘å®¹å™¨è®¿é—®"""
        
        @node
        def compute_with_context():
            # æµ‹è¯•ä¾èµ–æ³¨å…¥å®¹å™¨çš„çº¿ç¨‹å®‰å…¨æ€§
            context = AppContext()
            state = context.state()  # è·å–çº¿ç¨‹æœ¬åœ°çŠ¶æ€
            
            # æ¯ä¸ªçº¿ç¨‹åº”è¯¥æœ‰è‡ªå·±çš„çŠ¶æ€å­—å…¸
            thread_id = threading.current_thread().ident
            state[f'thread_{thread_id}'] = f'data_from_{thread_id}'
            
            return {'computed_by': thread_id, 'state_keys': list(state.keys())}
        
        results = []
        
        def worker():
            result = compute_with_context.run({})
            results.append(result)
        
        # å¯åŠ¨å¤šä¸ªçº¿ç¨‹
        threads = []
        for i in range(5):
            thread = threading.Thread(target=worker)
            threads.append(thread)
            thread.start()
        
        # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
        for thread in threads:
            thread.join()
        
        # éªŒè¯ç»“æœ
        assert len(results) == 5
        
        # æ¯ä¸ªçº¿ç¨‹åº”è¯¥æœ‰ä¸åŒçš„çŠ¶æ€
        for result in results:
            assert 'computed_by' in result
            assert 'state_keys' in result
            print(f"Thread result: {result}")
    
    def test_high_concurrency_stress(self):
        """é«˜å¹¶å‘å‹åŠ›æµ‹è¯•"""
        
        @node
        def stress_worker(iteration):
            # æ¨¡æ‹ŸCPUå¯†é›†å‹ä»»åŠ¡
            total = 0
            for i in range(1000):
                total += i * iteration
            
            return {'result': total, 'thread': threading.current_thread().ident}
        
        # ä½¿ç”¨ThreadPoolExecutorè¿›è¡Œå‹åŠ›æµ‹è¯•
        results = []
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
            # æäº¤100ä¸ªä»»åŠ¡
            futures = []
            for i in range(100):
                future = executor.submit(lambda x: stress_worker.run({'iteration': x}), i)
                futures.append(future)
            
            # æ”¶é›†ç»“æœ
            for future in concurrent.futures.as_completed(futures):
                result = future.result()
                results.append(result)
        
        # éªŒè¯æ‰€æœ‰ä»»åŠ¡éƒ½å®Œæˆäº†
        assert len(results) == 100
        
        # éªŒè¯ç»“æœçš„å”¯ä¸€æ€§ï¼ˆæ¯ä¸ªè¿­ä»£å€¼åº”è¯¥äº§ç”Ÿä¸åŒçš„ç»“æœï¼‰
        result_values = [r['result'] for r in results]
        assert len(set(result_values)) == len(result_values)  # æ‰€æœ‰ç»“æœéƒ½åº”è¯¥ä¸åŒ
        
        print(f"Completed {len(results)} concurrent tasks")


async def test_async_compatibility():
    """æµ‹è¯•å¼‚æ­¥å…¼å®¹æ€§ï¼ˆè™½ç„¶æ¡†æ¶æ˜¯åŒæ­¥çš„ï¼Œä½†ä¸åº”è¯¥åœ¨å¼‚æ­¥ç¯å¢ƒä¸­å´©æºƒï¼‰"""
    
    @node 
    def async_compatible_node(x):
        # åœ¨å¼‚æ­¥ç¯å¢ƒä¸­è¿è¡ŒåŒæ­¥èŠ‚ç‚¹
        return {'async_result': x * 2}
    
    # åœ¨å¼‚æ­¥ç¯å¢ƒä¸­è¿è¡ŒåŒæ­¥èŠ‚ç‚¹
    tasks = []
    for i in range(10):
        # ä½¿ç”¨run_in_executoråœ¨å¼‚æ­¥ç¯å¢ƒä¸­è¿è¡ŒåŒæ­¥ä»£ç 
        task = asyncio.get_event_loop().run_in_executor(
            None, 
            lambda x: async_compatible_node.run({'x': x}), 
            i
        )
        tasks.append(task)
    
    results = await asyncio.gather(*tasks)
    
    # éªŒè¯ç»“æœ
    assert len(results) == 10
    for i, result in enumerate(results):
        assert result['async_result'] == i * 2
    
    print(f"Async compatibility test passed with {len(results)} results")


def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("ğŸš€ å¼€å§‹å¹¶å‘å®‰å…¨æ€§æµ‹è¯•...")
    
    test_suite = TestConcurrentSafety()
    
    print("\n1. æµ‹è¯•çº¿ç¨‹æœ¬åœ°çŠ¶æ€éš”ç¦»...")
    test_suite.test_thread_local_state_isolation()
    print("âœ… çº¿ç¨‹æœ¬åœ°çŠ¶æ€éš”ç¦»æµ‹è¯•é€šè¿‡")
    
    print("\n2. æµ‹è¯•å¹¶è¡Œæ‰‡å‡ºçº¿ç¨‹å®‰å…¨æ€§...")
    test_suite.test_parallel_fan_out_thread_safety()
    print("âœ… å¹¶è¡Œæ‰‡å‡ºçº¿ç¨‹å®‰å…¨æ€§æµ‹è¯•é€šè¿‡")
    
    print("\n3. æµ‹è¯•å¹¶å‘å®¹å™¨è®¿é—®...")
    test_suite.test_concurrent_container_access()
    print("âœ… å¹¶å‘å®¹å™¨è®¿é—®æµ‹è¯•é€šè¿‡")
    
    print("\n4. é«˜å¹¶å‘å‹åŠ›æµ‹è¯•...")
    test_suite.test_high_concurrency_stress()
    print("âœ… é«˜å¹¶å‘å‹åŠ›æµ‹è¯•é€šè¿‡")
    
    print("\n5. å¼‚æ­¥å…¼å®¹æ€§æµ‹è¯•...")
    asyncio.run(test_async_compatibility())
    print("âœ… å¼‚æ­¥å…¼å®¹æ€§æµ‹è¯•é€šè¿‡")
    
    print("\nğŸ‰ æ‰€æœ‰å¹¶å‘å®‰å…¨æ€§æµ‹è¯•éƒ½å·²é€šè¿‡ï¼")


if __name__ == "__main__":
    run_all_tests()