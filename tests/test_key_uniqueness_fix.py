#!/usr/bin/env python3
"""
test_key_uniqueness_fix.py - æµ‹è¯•å¹¶è¡Œç»“æœé”®é‡å¤å¤„ç†ä¿®å¤çš„ä¸“é¡¹æµ‹è¯•

ä¸»è¦æµ‹è¯•åœºæ™¯ï¼š
1. æ­£å¸¸æƒ…å†µä¸‹æ— é‡å¤é”®çš„å¤„ç†
2. èŠ‚ç‚¹åç§°é‡å¤æ—¶çš„é”®å”¯ä¸€æ€§å¤„ç†
3. å¼‚å¸¸å¤„ç†è·¯å¾„çš„é”®é‡å¤å¤„ç†
4. æ··åˆåœºæ™¯ï¼ˆæ­£å¸¸å’Œå¼‚å¸¸ç»“æœçš„é”®å†²çªï¼‰
5. è¾¹ç•Œæƒ…å†µå’Œæ€§èƒ½æµ‹è¯•
"""

import time
import pytest
from typing import Dict, List, Any
from dataclasses import dataclass

import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from src.aetherflow import Node, ParallelResult, _generate_unique_result_key


# ============================================================================
# æµ‹è¯•è¾…åŠ©å·¥å…·å’Œæ¨¡æ‹ŸèŠ‚ç‚¹
# ============================================================================

@dataclass
class TestData:
    """æµ‹è¯•æ•°æ®ç»“æ„"""
    value: int
    name: str
    timestamp: float = None
    
    def __post_init__(self):
        if self.timestamp is None:
            self.timestamp = time.time()


class KeyTestHelper:
    """é”®é‡å¤æµ‹è¯•çš„è¾…åŠ©å·¥å…·ç±»"""
    
    @staticmethod
    def create_simple_node(name: str, multiplier: int = 2, should_fail: bool = False) -> Node:
        """åˆ›å»ºç®€å•çš„æµ‹è¯•èŠ‚ç‚¹"""
        def processor(data: TestData) -> TestData:
            if should_fail:
                raise ValueError(f"Node {name} intentionally failed")
            return TestData(
                value=data.value * multiplier,
                name=f"{name}_processed_{data.name}"
            )
        return Node(processor, name=name)
    
    @staticmethod
    def create_aggregator_node() -> Node:
        """åˆ›å»ºèšåˆèŠ‚ç‚¹"""
        def aggregator(parallel_results: Dict[str, ParallelResult]) -> Dict[str, Any]:
            successful_count = sum(1 for r in parallel_results.values() if r.success)
            failed_count = len(parallel_results) - successful_count
            
            return {
                'total_results': len(parallel_results),
                'successful_count': successful_count,
                'failed_count': failed_count,
                'result_keys': list(parallel_results.keys())
            }
        return Node(aggregator, name="key_aggregator")


# ============================================================================
# æµ‹è¯• _generate_unique_result_key å‡½æ•°
# ============================================================================

def test_generate_unique_key_no_conflict():
    """æµ‹è¯•æ— å†²çªæ—¶çš„é”®ç”Ÿæˆ"""
    print("\n=== æµ‹è¯•æ— å†²çªæ—¶çš„é”®ç”Ÿæˆ ===")
    
    existing_results = {
        'node1': 'some_result',
        'node2': 'another_result'
    }
    
    # æµ‹è¯•ä¸å†²çªçš„é”®
    key = _generate_unique_result_key('node3', existing_results)
    assert key == 'node3', f"æ— å†²çªæ—¶åº”è¯¥è¿”å›åŸå§‹é”®åï¼Œå®é™…è¿”å›: {key}"
    
    print(f"âœ… æ— å†²çªé”®ç”Ÿæˆæµ‹è¯•é€šè¿‡: {key}")


def test_generate_unique_key_with_conflict():
    """æµ‹è¯•æœ‰å†²çªæ—¶çš„é”®ç”Ÿæˆ"""
    print("\n=== æµ‹è¯•æœ‰å†²çªæ—¶çš„é”®ç”Ÿæˆ ===")
    
    existing_results = {
        'node1': 'result1',
        'node1[1]': 'result2',
        'node1[2]': 'result3'
    }
    
    # æµ‹è¯•å†²çªçš„é”®
    key = _generate_unique_result_key('node1', existing_results)
    assert key == 'node1[3]', f"å†²çªæ—¶åº”è¯¥è¿”å›node1[3]ï¼Œå®é™…è¿”å›: {key}"
    
    print(f"âœ… å†²çªé”®ç”Ÿæˆæµ‹è¯•é€šè¿‡: {key}")


def test_generate_unique_key_empty_dict():
    """æµ‹è¯•ç©ºå­—å…¸æ—¶çš„é”®ç”Ÿæˆ"""
    print("\n=== æµ‹è¯•ç©ºå­—å…¸æ—¶çš„é”®ç”Ÿæˆ ===")
    
    key = _generate_unique_result_key('any_name', {})
    assert key == 'any_name', f"ç©ºå­—å…¸æ—¶åº”è¯¥è¿”å›åŸå§‹é”®åï¼Œå®é™…è¿”å›: {key}"
    
    print(f"âœ… ç©ºå­—å…¸é”®ç”Ÿæˆæµ‹è¯•é€šè¿‡: {key}")


def test_generate_unique_key_sequential_conflicts():
    """æµ‹è¯•è¿ç»­å†²çªçš„é”®ç”Ÿæˆ"""
    print("\n=== æµ‹è¯•è¿ç»­å†²çªçš„é”®ç”Ÿæˆ ===")
    
    # æ¨¡æ‹Ÿè¿ç»­æ·»åŠ ç›¸åŒåç§°çš„é”®
    existing_results = {}
    generated_keys = []
    
    for i in range(5):
        key = _generate_unique_result_key('duplicate', existing_results)
        generated_keys.append(key)
        existing_results[key] = f'result_{i}'
    
    expected_keys = ['duplicate', 'duplicate[1]', 'duplicate[2]', 'duplicate[3]', 'duplicate[4]']
    assert generated_keys == expected_keys, f"è¿ç»­é”®ç”Ÿæˆä¸æ­£ç¡®: {generated_keys} vs {expected_keys}"
    
    print(f"âœ… è¿ç»­å†²çªé”®ç”Ÿæˆæµ‹è¯•é€šè¿‡: {generated_keys}")


# ============================================================================
# æµ‹è¯•å®é™…çš„å¹¶è¡Œæ‰§è¡Œé”®å¤„ç†
# ============================================================================

def test_parallel_execution_unique_names():
    """æµ‹è¯•å¹¶è¡Œæ‰§è¡Œä¸­æ— é‡å¤åç§°çš„æƒ…å†µ"""
    print("\n=== æµ‹è¯•å¹¶è¡Œæ‰§è¡Œæ— é‡å¤åç§° ===")
    
    # åˆ›å»ºæºèŠ‚ç‚¹
    def source_func(value: int) -> TestData:
        return TestData(value=value, name="source")
    
    source_node = Node(source_func, name="source")
    
    # åˆ›å»ºä¸åŒåç§°çš„ç›®æ ‡èŠ‚ç‚¹
    target_nodes = [
        KeyTestHelper.create_simple_node(f"unique_node_{i}", multiplier=i+1)
        for i in range(3)
    ]
    
    # æ‰§è¡Œå¹¶è¡Œå¤„ç†
    fan_out_pipeline = source_node.fan_out_to(target_nodes)
    results = fan_out_pipeline(10)
    
    print(f"ç»“æœæ•°é‡: {len(results)}")
    print(f"ç»“æœé”®: {list(results.keys())}")
    
    # éªŒè¯ç»“æœ
    assert len(results) == 3, f"åº”è¯¥æœ‰3ä¸ªç»“æœï¼Œå®é™…æœ‰{len(results)}ä¸ª"
    
    expected_keys = {'unique_node_0', 'unique_node_1', 'unique_node_2'}
    actual_keys = set(results.keys())
    assert actual_keys == expected_keys, f"é”®åº”è¯¥æ— é‡å¤: {actual_keys} vs {expected_keys}"
    
    # éªŒè¯æ‰€æœ‰ç»“æœéƒ½æˆåŠŸ
    for key, result in results.items():
        assert result.success, f"èŠ‚ç‚¹{key}æ‰§è¡Œåº”è¯¥æˆåŠŸ"
        print(f"  {key}: value={result.result.value}, success={result.success}")
    
    print("âœ… å¹¶è¡Œæ‰§è¡Œæ— é‡å¤åç§°æµ‹è¯•é€šè¿‡")


def test_parallel_execution_duplicate_names():
    """æµ‹è¯•å¹¶è¡Œæ‰§è¡Œä¸­é‡å¤åç§°çš„é”®å¤„ç†"""
    print("\n=== æµ‹è¯•å¹¶è¡Œæ‰§è¡Œé‡å¤åç§°é”®å¤„ç† ===")
    
    # åˆ›å»ºæºèŠ‚ç‚¹
    def source_func(value: int) -> TestData:
        return TestData(value=value, name="source")
    
    source_node = Node(source_func, name="source")
    
    # åˆ›å»ºç›¸åŒåç§°çš„ç›®æ ‡èŠ‚ç‚¹
    target_nodes = [
        KeyTestHelper.create_simple_node("duplicate_node", multiplier=i+1)
        for i in range(4)
    ]
    
    # æ‰§è¡Œå¹¶è¡Œå¤„ç†
    fan_out_pipeline = source_node.fan_out_to(target_nodes)
    results = fan_out_pipeline(5)
    
    print(f"ç»“æœæ•°é‡: {len(results)}")
    print(f"ç»“æœé”®: {sorted(results.keys())}")
    
    # éªŒè¯ç»“æœ
    assert len(results) == 4, f"åº”è¯¥æœ‰4ä¸ªç»“æœï¼Œå®é™…æœ‰{len(results)}ä¸ª"
    
    # éªŒè¯é”®çš„å”¯ä¸€æ€§å’Œé¢„æœŸæ ¼å¼
    expected_keys = {'duplicate_node', 'duplicate_node[1]', 'duplicate_node[2]', 'duplicate_node[3]'}
    actual_keys = set(results.keys())
    assert actual_keys == expected_keys, f"é‡å¤åç§°é”®å¤„ç†ä¸æ­£ç¡®: {actual_keys} vs {expected_keys}"
    
    # éªŒè¯æ‰€æœ‰ç»“æœéƒ½æˆåŠŸä¸”å€¼ä¸åŒï¼ˆä¸åŒçš„multiplierï¼‰
    values = []
    for key, result in results.items():
        assert result.success, f"èŠ‚ç‚¹{key}æ‰§è¡Œåº”è¯¥æˆåŠŸ"
        values.append(result.result.value)
        print(f"  {key}: value={result.result.value}, success={result.success}")
    
    # éªŒè¯å€¼çš„å”¯ä¸€æ€§ï¼ˆæ¯ä¸ªèŠ‚ç‚¹æœ‰ä¸åŒçš„multiplierï¼‰
    expected_values = {5, 10, 15, 20}  # 5*(1,2,3,4)
    actual_values = set(values)
    assert actual_values == expected_values, f"ç»“æœå€¼åº”è¯¥ä¸åŒ: {actual_values} vs {expected_values}"
    
    print("âœ… å¹¶è¡Œæ‰§è¡Œé‡å¤åç§°é”®å¤„ç†æµ‹è¯•é€šè¿‡")


def test_parallel_execution_with_failures():
    """æµ‹è¯•å¹¶è¡Œæ‰§è¡Œä¸­åŒ…å«å¼‚å¸¸çš„é”®å¤„ç†"""
    print("\n=== æµ‹è¯•å¹¶è¡Œæ‰§è¡Œå¼‚å¸¸é”®å¤„ç† ===")
    
    # åˆ›å»ºæºèŠ‚ç‚¹
    def source_func(value: int) -> TestData:
        return TestData(value=value, name="source")
    
    source_node = Node(source_func, name="source")
    
    # åˆ›å»ºæ··åˆèŠ‚ç‚¹ï¼šæ­£å¸¸å’Œå¤±è´¥èŠ‚ç‚¹éƒ½ä½¿ç”¨ç›¸åŒåç§°
    target_nodes = [
        KeyTestHelper.create_simple_node("mixed_node", multiplier=2, should_fail=False),
        KeyTestHelper.create_simple_node("mixed_node", multiplier=3, should_fail=True),
        KeyTestHelper.create_simple_node("mixed_node", multiplier=4, should_fail=False),
        KeyTestHelper.create_simple_node("mixed_node", multiplier=5, should_fail=True),
    ]
    
    # æ‰§è¡Œå¹¶è¡Œå¤„ç†
    fan_out_pipeline = source_node.fan_out_to(target_nodes)
    results = fan_out_pipeline(6)
    
    print(f"ç»“æœæ•°é‡: {len(results)}")
    print(f"ç»“æœé”®: {sorted(results.keys())}")
    
    # éªŒè¯ç»“æœ
    assert len(results) == 4, f"åº”è¯¥æœ‰4ä¸ªç»“æœï¼Œå®é™…æœ‰{len(results)}ä¸ª"
    
    # éªŒè¯é”®çš„å”¯ä¸€æ€§
    expected_keys = {'mixed_node', 'mixed_node[1]', 'mixed_node[2]', 'mixed_node[3]'}
    actual_keys = set(results.keys())
    assert actual_keys == expected_keys, f"æ··åˆåœºæ™¯é”®å¤„ç†ä¸æ­£ç¡®: {actual_keys} vs {expected_keys}"
    
    # ç»Ÿè®¡æˆåŠŸå’Œå¤±è´¥ç»“æœ
    successful_results = []
    failed_results = []
    
    for key, result in results.items():
        if result.success:
            successful_results.append((key, result))
            print(f"  âœ… {key}: value={result.result.value}")
        else:
            failed_results.append((key, result))
            print(f"  âŒ {key}: error={result.error}")
    
    # éªŒè¯ç»“æœç»Ÿè®¡
    assert len(successful_results) == 2, f"åº”è¯¥æœ‰2ä¸ªæˆåŠŸç»“æœï¼Œå®é™…æœ‰{len(successful_results)}ä¸ª"
    assert len(failed_results) == 2, f"åº”è¯¥æœ‰2ä¸ªå¤±è´¥ç»“æœï¼Œå®é™…æœ‰{len(failed_results)}ä¸ª"
    
    # éªŒè¯æˆåŠŸç»“æœçš„å€¼
    success_values = {result.result.value for _, result in successful_results}
    expected_success_values = {12, 24}  # 6*2, 6*4
    assert success_values == expected_success_values, f"æˆåŠŸç»“æœå€¼ä¸åŒ¹é…: {success_values} vs {expected_success_values}"
    
    # éªŒè¯å¤±è´¥ç»“æœåŒ…å«é”™è¯¯ä¿¡æ¯
    for key, result in failed_results:
        assert result.error is not None, f"å¤±è´¥ç»“æœ{key}åº”è¯¥åŒ…å«é”™è¯¯ä¿¡æ¯"
        assert "intentionally failed" in result.error, f"å¤±è´¥ç»“æœ{key}åº”è¯¥åŒ…å«é¢„æœŸçš„é”™è¯¯ä¿¡æ¯"
    
    print("âœ… å¹¶è¡Œæ‰§è¡Œå¼‚å¸¸é”®å¤„ç†æµ‹è¯•é€šè¿‡")


def test_fan_out_fan_in_key_handling():
    """æµ‹è¯•å®Œæ•´çš„fan_out_fan_inæµç¨‹ä¸­çš„é”®å¤„ç†"""
    print("\n=== æµ‹è¯•fan_out_fan_iné”®å¤„ç† ===")
    
    # åˆ›å»ºæºèŠ‚ç‚¹
    def source_func(value: int) -> TestData:
        return TestData(value=value, name="source")
    
    source_node = Node(source_func, name="source")
    
    # åˆ›å»ºé‡å¤åç§°çš„ç›®æ ‡èŠ‚ç‚¹
    target_nodes = [
        KeyTestHelper.create_simple_node("fanout_target", multiplier=i+1)
        for i in range(3)
    ]
    
    # åˆ›å»ºèšåˆèŠ‚ç‚¹
    aggregator_node = KeyTestHelper.create_aggregator_node()
    
    # æ‰§è¡Œå®Œæ•´çš„fan_out_fan_inæµç¨‹
    pipeline = source_node.fan_out_in(target_nodes, aggregator_node)
    result = pipeline(8)
    
    print(f"èšåˆç»“æœ: {result}")
    
    # éªŒè¯èšåˆç»“æœ
    assert isinstance(result, dict), "èšåˆç»“æœåº”è¯¥æ˜¯å­—å…¸"
    assert result['total_results'] == 3, f"åº”è¯¥å¤„ç†3ä¸ªç»“æœï¼Œå®é™…å¤„ç†äº†{result['total_results']}ä¸ª"
    assert result['successful_count'] == 3, f"åº”è¯¥æœ‰3ä¸ªæˆåŠŸç»“æœï¼Œå®é™…æœ‰{result['successful_count']}ä¸ª"
    assert result['failed_count'] == 0, f"åº”è¯¥æœ‰0ä¸ªå¤±è´¥ç»“æœï¼Œå®é™…æœ‰{result['failed_count']}ä¸ª"
    
    # éªŒè¯ç»“æœé”®çš„æ ¼å¼
    result_keys = set(result['result_keys'])
    expected_keys = {'fanout_target', 'fanout_target[1]', 'fanout_target[2]'}
    assert result_keys == expected_keys, f"èšåˆå™¨æ¥æ”¶åˆ°çš„é”®ä¸æ­£ç¡®: {result_keys} vs {expected_keys}"
    
    print(f"âœ… fan_out_fan_iné”®å¤„ç†æµ‹è¯•é€šè¿‡ï¼Œå¤„ç†çš„é”®: {result['result_keys']}")


# ============================================================================
# æ€§èƒ½å’Œè¾¹ç•Œæƒ…å†µæµ‹è¯•
# ============================================================================

def test_large_scale_duplicate_keys():
    """æµ‹è¯•å¤§é‡é‡å¤é”®çš„æ€§èƒ½"""
    print("\n=== æµ‹è¯•å¤§é‡é‡å¤é”®æ€§èƒ½ ===")
    
    start_time = time.time()
    
    # æ¨¡æ‹Ÿå¤§é‡é‡å¤é”®çš„åœºæ™¯
    existing_results = {}
    generated_keys = []
    
    # ç”Ÿæˆ100ä¸ªé‡å¤é”®
    for i in range(100):
        key = _generate_unique_result_key('performance_test', existing_results)
        generated_keys.append(key)
        existing_results[key] = f'result_{i}'
    
    end_time = time.time()
    execution_time = end_time - start_time
    
    print(f"ç”Ÿæˆ100ä¸ªé”®è€—æ—¶: {execution_time:.4f}ç§’")
    print(f"å‰10ä¸ªé”®: {generated_keys[:10]}")
    print(f"å10ä¸ªé”®: {generated_keys[-10:]}")
    
    # éªŒè¯æ€§èƒ½ï¼ˆåº”è¯¥åœ¨åˆç†æ—¶é—´å†…å®Œæˆï¼‰
    assert execution_time < 1.0, f"æ€§èƒ½æµ‹è¯•è¶…æ—¶: {execution_time}ç§’"
    
    # éªŒè¯é”®çš„å”¯ä¸€æ€§
    assert len(set(generated_keys)) == 100, "æ‰€æœ‰ç”Ÿæˆçš„é”®åº”è¯¥éƒ½æ˜¯å”¯ä¸€çš„"
    
    # éªŒè¯é”®çš„æ ¼å¼
    assert generated_keys[0] == 'performance_test', "ç¬¬ä¸€ä¸ªé”®åº”è¯¥æ˜¯åŸå§‹åç§°"
    assert generated_keys[1] == 'performance_test[1]', "ç¬¬äºŒä¸ªé”®åº”è¯¥æ˜¯å¸¦[1]åç¼€"
    assert generated_keys[99] == 'performance_test[99]', "ç¬¬100ä¸ªé”®åº”è¯¥æ˜¯å¸¦[99]åç¼€"
    
    print("âœ… å¤§é‡é‡å¤é”®æ€§èƒ½æµ‹è¯•é€šè¿‡")


def test_edge_cases():
    """æµ‹è¯•è¾¹ç•Œæƒ…å†µ"""
    print("\n=== æµ‹è¯•è¾¹ç•Œæƒ…å†µ ===")
    
    # æµ‹è¯•ç©ºå­—ç¬¦ä¸²é”®å
    key1 = _generate_unique_result_key('', {})
    assert key1 == '', "ç©ºå­—ç¬¦ä¸²é”®ååº”è¯¥æ­£å¸¸å¤„ç†"
    
    # æµ‹è¯•åŒ…å«ç‰¹æ®Šå­—ç¬¦çš„é”®å
    special_name = 'node@#$%^&*()'
    key2 = _generate_unique_result_key(special_name, {})
    assert key2 == special_name, "ç‰¹æ®Šå­—ç¬¦é”®ååº”è¯¥æ­£å¸¸å¤„ç†"
    
    # æµ‹è¯•æé•¿çš„é”®å
    long_name = 'very_long_node_name_' * 10
    key3 = _generate_unique_result_key(long_name, {})
    assert key3 == long_name, "æé•¿é”®ååº”è¯¥æ­£å¸¸å¤„ç†"
    
    # æµ‹è¯•åŒ…å«æ•°å­—çš„é”®åå†²çª
    existing = {'node123': 'result'}
    key4 = _generate_unique_result_key('node123', existing)
    assert key4 == 'node123[1]', "åŒ…å«æ•°å­—çš„é”®åå†²çªåº”è¯¥æ­£å¸¸å¤„ç†"
    
    print("âœ… è¾¹ç•Œæƒ…å†µæµ‹è¯•é€šè¿‡")


if __name__ == "__main__":
    print("=== å¹¶è¡Œç»“æœé”®é‡å¤å¤„ç†ä¿®å¤æµ‹è¯• ===")
    
    try:
        # æµ‹è¯•æ ¸å¿ƒå‡½æ•°
        test_generate_unique_key_no_conflict()
        test_generate_unique_key_with_conflict()
        test_generate_unique_key_empty_dict()
        test_generate_unique_key_sequential_conflicts()
        
        # æµ‹è¯•å®é™…å¹¶è¡Œæ‰§è¡Œ
        test_parallel_execution_unique_names()
        test_parallel_execution_duplicate_names()
        test_parallel_execution_with_failures()
        test_fan_out_fan_in_key_handling()
        
        # æµ‹è¯•æ€§èƒ½å’Œè¾¹ç•Œæƒ…å†µ
        test_large_scale_duplicate_keys()
        test_edge_cases()
        
        print("\nğŸ‰ æ‰€æœ‰é”®é‡å¤å¤„ç†ä¿®å¤æµ‹è¯•é€šè¿‡ï¼")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()