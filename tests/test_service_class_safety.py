#!/usr/bin/env python3
"""
å¤æ‚æœåŠ¡ç±»çš„çº¿ç¨‹å®‰å…¨æµ‹è¯•

éªŒè¯ThreadLocalSingletonå¯¹å¤æ‚æœåŠ¡å¯¹è±¡çš„å¤„ç†æ˜¯å¦æ­£ç¡®ï¼Œ
åŒ…æ‹¬æ„é€ å™¨çº¿ç¨‹å®‰å…¨æ€§ã€æ–¹æ³•é‡å…¥æ€§ã€å†…å­˜ç®¡ç†ç­‰æ–¹é¢ã€‚
"""

import threading
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass
from typing import List, Dict, Any
from dependency_injector import containers, providers

import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))
from src.aetherflow import node, BaseFlowContext


# æµ‹è¯•ç”¨çš„å¤æ‚æœåŠ¡ç±»
class StatefulService:
    """æœ‰çŠ¶æ€æœåŠ¡ç±»ï¼Œç”¨äºæµ‹è¯•ThreadLocalSingletonè¡Œä¸º"""
    
    def __init__(self, service_id: str = None):
        self.service_id = service_id or f"service_{threading.current_thread().ident}"
        self.call_count = 0
        self.operation_history = []
        self.thread_id = threading.current_thread().ident
        self.creation_time = time.time()
        print(f"âœ… Created {self.service_id} in thread {self.thread_id}")
    
    def increment_counter(self):
        """çº¿ç¨‹å®‰å…¨çš„è®¡æ•°å™¨æ“ä½œ"""
        self.call_count += 1
        operation = {
            'operation': 'increment',
            'count': self.call_count,
            'thread_id': threading.current_thread().ident,
            'timestamp': time.time()
        }
        self.operation_history.append(operation)
        return self.call_count
    
    def get_stats(self):
        """è·å–æœåŠ¡ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'service_id': self.service_id,
            'creation_thread': self.thread_id,
            'current_thread': threading.current_thread().ident,
            'call_count': self.call_count,
            'operations': len(self.operation_history),
            'uptime': time.time() - self.creation_time
        }
    
    def reset_state(self):
        """é‡ç½®çŠ¶æ€"""
        self.call_count = 0
        self.operation_history.clear()


class DatabaseMockService:
    """æ¨¡æ‹Ÿæ•°æ®åº“æœåŠ¡ï¼Œæµ‹è¯•èµ„æºç®¡ç†"""
    
    def __init__(self):
        self.connection_count = 0
        self.queries_executed = []
        self.thread_id = threading.current_thread().ident
        self.is_connected = False
        self._connect()
    
    def _connect(self):
        """æ¨¡æ‹Ÿæ•°æ®åº“è¿æ¥"""
        time.sleep(0.001)  # æ¨¡æ‹Ÿè¿æ¥å»¶è¿Ÿ
        self.is_connected = True
        self.connection_count += 1
        print(f"ğŸ”Œ DB connected in thread {self.thread_id} (connection #{self.connection_count})")
    
    def execute_query(self, query: str):
        """æ‰§è¡ŒæŸ¥è¯¢"""
        if not self.is_connected:
            raise RuntimeError("Database not connected")
        
        result = {
            'query': query,
            'thread_id': threading.current_thread().ident,
            'execution_time': time.time(),
            'connection_id': self.connection_count
        }
        self.queries_executed.append(result)
        return result
    
    def get_connection_info(self):
        """è·å–è¿æ¥ä¿¡æ¯"""
        return {
            'thread_id': self.thread_id,
            'current_thread': threading.current_thread().ident,
            'connection_count': self.connection_count,
            'queries_count': len(self.queries_executed),
            'is_connected': self.is_connected
        }


# æµ‹è¯•ä¸Šä¸‹æ–‡å®¹å™¨
class ServiceTestContext(BaseFlowContext):
    """æœåŠ¡æµ‹è¯•ä¸Šä¸‹æ–‡ - ä½¿ç”¨ThreadLocalSingleton"""
    state = providers.ThreadLocalSingleton(dict)
    stateful_service = providers.ThreadLocalSingleton(StatefulService)
    db_service = providers.ThreadLocalSingleton(DatabaseMockService)


class SharedServiceTestContext(BaseFlowContext):
    """å…±äº«æœåŠ¡æµ‹è¯•ä¸Šä¸‹æ–‡ - ä½¿ç”¨Singletonå¯¹æ¯”"""
    state = providers.Singleton(dict)
    shared_service = providers.Singleton(StatefulService, service_id="shared_service")


# æµ‹è¯•èŠ‚ç‚¹
@node
def service_operation(data, stateful_service: StatefulService):
    """ä½¿ç”¨æœ‰çŠ¶æ€æœåŠ¡çš„æ“ä½œèŠ‚ç‚¹"""
    thread_id = threading.current_thread().ident
    
    # æ‰§è¡Œå¤šä¸ªæ“ä½œ
    count1 = stateful_service.increment_counter()
    count2 = stateful_service.increment_counter()
    
    # è·å–ç»Ÿè®¡ä¿¡æ¯
    stats = stateful_service.get_stats()
    
    return {
        'thread_id': thread_id,
        'data': data,
        'count1': count1,
        'count2': count2,
        'service_stats': stats
    }


@node
def database_operation(query, db_service: DatabaseMockService):
    """æ•°æ®åº“æ“ä½œèŠ‚ç‚¹"""
    result = db_service.execute_query(query)
    connection_info = db_service.get_connection_info()
    
    return {
        'query_result': result,
        'connection_info': connection_info
    }


@node
def complex_service_workflow(data, stateful_service: StatefulService, db_service: DatabaseMockService):
    """å¤æ‚æœåŠ¡å·¥ä½œæµç¨‹"""
    thread_id = threading.current_thread().ident
    
    # ä½¿ç”¨å¤šä¸ªæœåŠ¡
    service_count = stateful_service.increment_counter()
    db_result = db_service.execute_query(f"SELECT * FROM users WHERE id={data}")
    
    # éªŒè¯æœåŠ¡å®ä¾‹çš„çº¿ç¨‹å½’å±
    service_stats = stateful_service.get_stats()
    db_info = db_service.get_connection_info()
    
    return {
        'thread_id': thread_id,
        'data': data,
        'service_count': service_count,
        'db_result': db_result,
        'service_thread_match': service_stats['creation_thread'] == thread_id,
        'db_thread_match': db_info['thread_id'] == thread_id,
        'service_stats': service_stats,
        'db_info': db_info
    }


class TestServiceClassSafety:
    """å¤æ‚æœåŠ¡ç±»çº¿ç¨‹å®‰å…¨æµ‹è¯•å¥—ä»¶"""
    
    def test_thread_local_service_instances(self):
        """æµ‹è¯•çº¿ç¨‹æœ¬åœ°æœåŠ¡å®ä¾‹åˆ›å»º"""
        context = ServiceTestContext()
        results = []
        
        def worker(worker_id):
            result = service_operation.run({'data': worker_id}, context)
            results.append(result)
        
        # å¯åŠ¨å¤šä¸ªçº¿ç¨‹
        threads = []
        for i in range(5):
            t = threading.Thread(target=worker, args=(i,))
            threads.append(t)
            t.start()
        
        for t in threads:
            t.join()
        
        # éªŒè¯ç»“æœ
        assert len(results) == 5
        
        # æ¯ä¸ªçº¿ç¨‹åº”è¯¥æœ‰ç‹¬ç«‹çš„æœåŠ¡å®ä¾‹
        service_threads = set()
        for result in results:
            stats = result['service_stats']
            service_threads.add(stats['creation_thread'])
            
            # æœåŠ¡åº”è¯¥åœ¨åˆ›å»ºå®ƒçš„çº¿ç¨‹ä¸­è¿è¡Œ
            assert stats['creation_thread'] == result['thread_id']
            assert stats['current_thread'] == result['thread_id']
        
        # åº”è¯¥æœ‰5ä¸ªä¸åŒçš„çº¿ç¨‹åˆ›å»ºäº†æœåŠ¡å®ä¾‹
        assert len(service_threads) == 5
        print(f"âœ… åˆ›å»ºäº† {len(service_threads)} ä¸ªç‹¬ç«‹çš„æœåŠ¡å®ä¾‹")
    
    def test_service_state_isolation(self):
        """æµ‹è¯•æœåŠ¡çŠ¶æ€éš”ç¦»"""
        context = ServiceTestContext()
        results = []
        
        def worker(worker_id):
            # æ¯ä¸ªå·¥ä½œçº¿ç¨‹æ‰§è¡Œä¸åŒæ¬¡æ•°çš„æ“ä½œ
            operations = worker_id + 1
            result = None
            
            for i in range(operations):
                result = service_operation.run({'data': f"{worker_id}_{i}"}, context)
            
            results.append({
                'worker_id': worker_id,
                'operations': operations,
                'final_result': result
            })
        
        # å¯åŠ¨å·¥ä½œçº¿ç¨‹
        threads = []
        for i in range(4):
            t = threading.Thread(target=worker, args=(i,))
            threads.append(t)
            t.start()
        
        for t in threads:
            t.join()
        
        # éªŒè¯çŠ¶æ€éš”ç¦»
        for result in results:
            worker_id = result['worker_id']
            operations = result['operations']
            final_result = result['final_result']
            
            # æ¯ä¸ªworkerçš„æœ€ç»ˆè®¡æ•°åº”è¯¥ç­‰äºå…¶æ“ä½œæ¬¡æ•°çš„2å€ï¼ˆæ¯æ¬¡service_operationè°ƒç”¨incrementä¸¤æ¬¡ï¼‰
            expected_count = operations * 2
            actual_count = final_result['service_stats']['call_count']
            
            assert actual_count == expected_count, f"Worker {worker_id}: expected {expected_count}, got {actual_count}"
        
        print("âœ… æœåŠ¡çŠ¶æ€åœ¨çº¿ç¨‹é—´å®Œå…¨éš”ç¦»")
    
    def test_database_service_isolation(self):
        """æµ‹è¯•æ•°æ®åº“æœåŠ¡çº¿ç¨‹éš”ç¦»"""
        context = ServiceTestContext()
        results = []
        
        def worker(worker_id):
            queries = [f"SELECT {worker_id}_{i}" for i in range(3)]
            worker_results = []
            
            for query in queries:
                result = database_operation.run({'query': query}, context)
                worker_results.append(result)
            
            results.append({
                'worker_id': worker_id,
                'queries': queries,
                'results': worker_results
            })
        
        # å¯åŠ¨å¤šä¸ªçº¿ç¨‹
        threads = []
        for i in range(3):
            t = threading.Thread(target=worker, args=(i,))
            threads.append(t)
            t.start()
        
        for t in threads:
            t.join()
        
        # éªŒè¯æ•°æ®åº“è¿æ¥éš”ç¦»
        connection_threads = set()
        for worker_result in results:
            for result in worker_result['results']:
                conn_info = result['connection_info']
                
                # æ•°æ®åº“æœåŠ¡åº”è¯¥åœ¨å½“å‰çº¿ç¨‹ä¸­åˆ›å»º
                assert conn_info['thread_id'] == conn_info['current_thread']
                connection_threads.add(conn_info['thread_id'])
        
        # åº”è¯¥æœ‰3ä¸ªä¸åŒçš„æ•°æ®åº“è¿æ¥
        assert len(connection_threads) == 3
        print(f"âœ… åˆ›å»ºäº† {len(connection_threads)} ä¸ªç‹¬ç«‹çš„æ•°æ®åº“è¿æ¥")
    
    def test_complex_service_workflow(self):
        """æµ‹è¯•å¤æ‚æœåŠ¡å·¥ä½œæµç¨‹"""
        context = ServiceTestContext()
        results = []
        
        def worker(worker_id):
            # æ¯ä¸ªworkerå¤„ç†å¤šä¸ªæ•°æ®é¡¹
            data_items = [worker_id * 10 + i for i in range(3)]
            worker_results = []
            
            for data in data_items:
                result = complex_service_workflow.run({'data': data}, context)
                worker_results.append(result)
            
            results.append({
                'worker_id': worker_id,
                'results': worker_results
            })
        
        # å¯åŠ¨å·¥ä½œçº¿ç¨‹
        threads = []
        for i in range(4):
            t = threading.Thread(target=worker, args=(i,))
            threads.append(t)
            t.start()
        
        for t in threads:
            t.join()
        
        # éªŒè¯å¤æ‚å·¥ä½œæµç¨‹çš„æ­£ç¡®æ€§
        for worker_result in results:
            worker_id = worker_result['worker_id']
            
            for i, result in enumerate(worker_result['results']):
                # éªŒè¯çº¿ç¨‹åŒ¹é…
                assert result['service_thread_match'], f"Worker {worker_id}: service thread mismatch"
                assert result['db_thread_match'], f"Worker {worker_id}: database thread mismatch"
                
                # éªŒè¯æœåŠ¡è®¡æ•°çš„ç´¯ç§¯æ€§
                expected_count = i + 1  # æ¯æ¬¡è°ƒç”¨incrementä¸€æ¬¡
                actual_count = result['service_count']
                assert actual_count == expected_count, f"Worker {worker_id}, call {i}: expected {expected_count}, got {actual_count}"
        
        print("âœ… å¤æ‚æœåŠ¡å·¥ä½œæµç¨‹çº¿ç¨‹å®‰å…¨éªŒè¯é€šè¿‡")
    
    def test_service_performance_under_load(self):
        """æµ‹è¯•æœåŠ¡åœ¨é«˜è´Ÿè½½ä¸‹çš„æ€§èƒ½"""
        context = ServiceTestContext()
        
        def worker(worker_id):
            start_time = time.time()
            results = []
            
            # æ‰§è¡Œ100æ¬¡æ“ä½œ
            for i in range(100):
                result = service_operation.run({'data': f"{worker_id}_{i}"}, context)
                results.append(result)
            
            end_time = time.time()
            return {
                'worker_id': worker_id,
                'execution_time': end_time - start_time,
                'operations': len(results),
                'final_count': results[-1]['service_stats']['call_count']
            }
        
        # ä½¿ç”¨ThreadPoolExecutorè¿›è¡Œé«˜å¹¶å‘æµ‹è¯•
        start_time = time.time()
        
        with ThreadPoolExecutor(max_workers=10) as executor:
            futures = [executor.submit(worker, i) for i in range(10)]
            results = [future.result() for future in as_completed(futures)]
        
        end_time = time.time()
        total_time = end_time - start_time
        
        # éªŒè¯ç»“æœ
        total_operations = sum(r['operations'] for r in results)
        
        # æ¯ä¸ªworkeråº”è¯¥æ‰§è¡Œäº†200æ¬¡incrementæ“ä½œï¼ˆ100æ¬¡service_operationï¼Œæ¯æ¬¡2ä¸ªincrementï¼‰
        for result in results:
            assert result['final_count'] == 200, f"Worker {result['worker_id']}: expected 200, got {result['final_count']}"
        
        # æ€§èƒ½ç»Ÿè®¡
        avg_time_per_worker = sum(r['execution_time'] for r in results) / len(results)
        operations_per_second = total_operations / total_time
        
        print(f"âœ… é«˜è´Ÿè½½æµ‹è¯•å®Œæˆ:")
        print(f"   - æ€»æ“ä½œæ•°: {total_operations}")
        print(f"   - æ€»æ—¶é—´: {total_time:.2f}s")
        print(f"   - å¹³å‡æ¯workeræ—¶é—´: {avg_time_per_worker:.2f}s")
        print(f"   - æ“ä½œ/ç§’: {operations_per_second:.0f}")
        
        # æ€§èƒ½æ–­è¨€ï¼ˆæ ¹æ®å®é™…æƒ…å†µè°ƒæ•´ï¼‰
        assert operations_per_second > 1000, f"Performance too low: {operations_per_second} ops/sec"
    
    def test_shared_vs_thread_local_comparison(self):
        """å¯¹æ¯”å…±äº«æœåŠ¡å’Œçº¿ç¨‹æœ¬åœ°æœåŠ¡çš„è¡Œä¸º"""
        thread_local_context = ServiceTestContext()
        shared_context = SharedServiceTestContext()
        
        results = {
            'thread_local': [],
            'shared': []
        }
        
        def thread_local_worker(worker_id):
            result = service_operation.run({'data': worker_id}, thread_local_context)
            results['thread_local'].append(result)
        
        def shared_worker(worker_id):
            # æ³¨æ„ï¼šshared contextä½¿ç”¨ä¸åŒçš„èŠ‚ç‚¹ï¼Œå› ä¸ºæœåŠ¡åä¸åŒ
            @node
            def shared_service_operation(data, shared_service: StatefulService):
                thread_id = threading.current_thread().ident
                count1 = shared_service.increment_counter()
                count2 = shared_service.increment_counter()
                stats = shared_service.get_stats()
                return {
                    'thread_id': thread_id,
                    'data': data,
                    'count1': count1,
                    'count2': count2,
                    'service_stats': stats
                }
            
            result = shared_service_operation.run({'data': worker_id}, shared_context)
            results['shared'].append(result)
        
        # å¯åŠ¨çº¿ç¨‹æœ¬åœ°æµ‹è¯•
        threads = []
        for i in range(3):
            t = threading.Thread(target=thread_local_worker, args=(i,))
            threads.append(t)
            t.start()
        
        for t in threads:
            t.join()
        
        # å¯åŠ¨å…±äº«çŠ¶æ€æµ‹è¯•
        threads = []
        for i in range(3):
            t = threading.Thread(target=shared_worker, args=(i,))
            threads.append(t)
            t.start()
        
        for t in threads:
            t.join()
        
        # åˆ†æç»“æœå·®å¼‚
        print("\nğŸ” çº¿ç¨‹æœ¬åœ° vs å…±äº«æœåŠ¡å¯¹æ¯”:")
        
        # çº¿ç¨‹æœ¬åœ°ï¼šæ¯ä¸ªçº¿ç¨‹ç‹¬ç«‹è®¡æ•°
        thread_local_counts = [r['service_stats']['call_count'] for r in results['thread_local']]
        print(f"   çº¿ç¨‹æœ¬åœ°è®¡æ•°: {thread_local_counts}")
        assert all(count == 2 for count in thread_local_counts), "çº¿ç¨‹æœ¬åœ°æœåŠ¡è®¡æ•°åº”è¯¥éƒ½æ˜¯2"
        
        # å…±äº«æœåŠ¡ï¼šå…¨å±€ç´¯ç§¯è®¡æ•°
        shared_counts = [r['count2'] for r in results['shared']]
        shared_counts.sort()  # æ’åºå› ä¸ºçº¿ç¨‹æ‰§è¡Œé¡ºåºä¸ç¡®å®š
        print(f"   å…±äº«æœåŠ¡è®¡æ•°: {shared_counts}")
        
        # å…±äº«æœåŠ¡çš„è®¡æ•°åº”è¯¥æ˜¯ç´¯ç§¯çš„
        assert max(shared_counts) == 6, f"å…±äº«æœåŠ¡æœ€å¤§è®¡æ•°åº”è¯¥æ˜¯6ï¼Œå®é™…æ˜¯{max(shared_counts)}"
        
        print("âœ… ä¸¤ç§æ¨¡å¼çš„è¡Œä¸ºå·®å¼‚éªŒè¯å®Œæˆ")
    
    def test_memory_cleanup(self):
        """æµ‹è¯•çº¿ç¨‹ç»“æŸåçš„å†…å­˜æ¸…ç†"""
        import gc
        import weakref
        
        context = ServiceTestContext()
        service_refs = []
        
        def worker_with_ref_tracking(worker_id):
            # è·å–æœåŠ¡å®ä¾‹å¹¶åˆ›å»ºå¼±å¼•ç”¨
            result = service_operation.run({'data': worker_id}, context)
            
            # é€šè¿‡contextç›´æ¥è·å–æœåŠ¡å®ä¾‹ä»¥åˆ›å»ºå¼±å¼•ç”¨
            service_instance = context.stateful_service()
            weak_ref = weakref.ref(service_instance)
            service_refs.append({
                'worker_id': worker_id,
                'weak_ref': weak_ref,
                'service_id': service_instance.service_id
            })
            
            return result
        
        # å¯åŠ¨å¹¶ç­‰å¾…çº¿ç¨‹å®Œæˆ
        threads = []
        for i in range(3):
            t = threading.Thread(target=worker_with_ref_tracking, args=(i,))
            threads.append(t)
            t.start()
        
        for t in threads:
            t.join()
        
        # å¼ºåˆ¶åƒåœ¾å›æ”¶
        gc.collect()
        time.sleep(0.1)  # ç»™ç³»ç»Ÿä¸€ç‚¹æ—¶é—´æ¸…ç†
        gc.collect()
        
        # æ£€æŸ¥å¼±å¼•ç”¨çŠ¶æ€
        print(f"\nğŸ§¹ å†…å­˜æ¸…ç†æ£€æŸ¥:")
        alive_refs = 0
        for ref_info in service_refs:
            is_alive = ref_info['weak_ref']() is not None
            status = "å­˜æ´»" if is_alive else "å·²æ¸…ç†"
            print(f"   Service {ref_info['service_id']}: {status}")
            if is_alive:
                alive_refs += 1
        
        # æ³¨æ„ï¼šThreadLocalå¯¹è±¡å¯èƒ½ä¸ä¼šç«‹å³è¢«å›æ”¶ï¼Œè¿™æ˜¯æ­£å¸¸çš„
        # è¿™ä¸ªæµ‹è¯•ä¸»è¦æ˜¯ä¸ºäº†è§‚å¯Ÿå†…å­˜ç®¡ç†è¡Œä¸º
        print(f"   å­˜æ´»çš„æœåŠ¡å®ä¾‹: {alive_refs}/{len(service_refs)}")


def run_service_safety_tests():
    """è¿è¡Œæ‰€æœ‰æœåŠ¡å®‰å…¨æµ‹è¯•"""
    print("ğŸš€ å¼€å§‹å¤æ‚æœåŠ¡ç±»çº¿ç¨‹å®‰å…¨æµ‹è¯•...")
    
    test_suite = TestServiceClassSafety()
    
    try:
        test_suite.test_thread_local_service_instances()
        print("âœ… çº¿ç¨‹æœ¬åœ°æœåŠ¡å®ä¾‹æµ‹è¯•é€šè¿‡")
        
        test_suite.test_service_state_isolation()
        print("âœ… æœåŠ¡çŠ¶æ€éš”ç¦»æµ‹è¯•é€šè¿‡")
        
        test_suite.test_database_service_isolation()
        print("âœ… æ•°æ®åº“æœåŠ¡éš”ç¦»æµ‹è¯•é€šè¿‡")
        
        test_suite.test_complex_service_workflow()
        print("âœ… å¤æ‚æœåŠ¡å·¥ä½œæµç¨‹æµ‹è¯•é€šè¿‡")
        
        test_suite.test_service_performance_under_load()
        print("âœ… é«˜è´Ÿè½½æ€§èƒ½æµ‹è¯•é€šè¿‡")
        
        test_suite.test_shared_vs_thread_local_comparison()
        print("âœ… å…±äº«vsçº¿ç¨‹æœ¬åœ°å¯¹æ¯”æµ‹è¯•é€šè¿‡")
        
        test_suite.test_memory_cleanup()
        print("âœ… å†…å­˜æ¸…ç†æµ‹è¯•å®Œæˆ")
        
        print("\nğŸ‰ æ‰€æœ‰å¤æ‚æœåŠ¡ç±»çº¿ç¨‹å®‰å…¨æµ‹è¯•é€šè¿‡ï¼")
        return True
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == '__main__':
    success = run_service_safety_tests()
    exit(0 if success else 1)