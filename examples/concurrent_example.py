#!/usr/bin/env python3
"""
å¹¶å‘å®‰å…¨ç¤ºä¾‹

å±•ç¤ºAetherFlowæ¡†æ¶åœ¨å¤šçº¿ç¨‹ç¯å¢ƒä¸‹çš„çº¿ç¨‹å®‰å…¨ç‰¹æ€§ã€‚
è¿™ä¸ªç¤ºä¾‹è¯æ˜äº†ä½¿ç”¨ThreadLocalSingletonåï¼Œæ¯ä¸ªçº¿ç¨‹éƒ½æœ‰ç‹¬ç«‹çš„çŠ¶æ€ç©ºé—´ã€‚
"""

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

import threading
import time
import concurrent.futures
from src.aetherflow import node, AppContext


# å®šä¹‰ä¸€äº›ç¤ºä¾‹èŠ‚ç‚¹
@node
def init_counter(start_value):
    """åˆå§‹åŒ–è®¡æ•°å™¨"""
    return {'counter': start_value}


@node  
def increment(counter):
    """é€’å¢è®¡æ•°å™¨"""
    time.sleep(0.01)  # æ¨¡æ‹Ÿä¸€äº›å¤„ç†æ—¶é—´
    return {'counter': counter + 1}


@node
def multiply(counter, factor):
    """å°†è®¡æ•°å™¨ä¹˜ä»¥å› å­"""
    return {'counter': counter * factor}


@node
def get_thread_info(counter):
    """è·å–çº¿ç¨‹ä¿¡æ¯å’Œæœ€ç»ˆç»“æœ"""
    thread_id = threading.current_thread().ident
    return {
        'final_counter': counter,
        'thread_id': thread_id,
        'thread_name': threading.current_thread().name
    }


def concurrent_demo():
    """å¹¶å‘æ‰§è¡Œæ¼”ç¤º"""
    print("ğŸš€ AetherFlow å¹¶å‘å®‰å…¨æ¼”ç¤º")
    print("=" * 50)
    
    # åˆ›å»ºä¸€ä¸ªå¤åˆæµç¨‹
    workflow = (init_counter
                .then(increment)
                .then(increment) 
                .then(multiply)
                .then(get_thread_info))
    
    results = {}
    
    def worker(worker_id):
        """å·¥ä½œçº¿ç¨‹å‡½æ•°"""
        print(f"âš¡ å·¥ä½œçº¿ç¨‹ {worker_id} å¼€å§‹æ‰§è¡Œ...")
        
        # æ¯ä¸ªçº¿ç¨‹ä½¿ç”¨ä¸åŒçš„åˆå§‹å€¼å’Œå› å­
        initial_state = {
            'start_value': worker_id * 10,
            'factor': worker_id + 1
        }
        
        # æ‰§è¡Œå·¥ä½œæµç¨‹
        result = workflow.run(initial_state)
        
        results[worker_id] = result
        print(f"âœ… å·¥ä½œçº¿ç¨‹ {worker_id} å®Œæˆ: æœ€ç»ˆè®¡æ•°å™¨ = {result['final_counter']}")
    
    # å¯åŠ¨å¤šä¸ªå·¥ä½œçº¿ç¨‹
    threads = []
    num_workers = 5
    
    print(f"\nå¯åŠ¨ {num_workers} ä¸ªå¹¶å‘å·¥ä½œçº¿ç¨‹...")
    
    for i in range(num_workers):
        thread = threading.Thread(target=worker, args=(i,), name=f"Worker-{i}")
        threads.append(thread)
        thread.start()
    
    # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
    for thread in threads:
        thread.join()
    
    # æ˜¾ç¤ºç»“æœ
    print(f"\nğŸ“Š æœ€ç»ˆç»“æœæ±‡æ€»:")
    print("-" * 30)
    
    for worker_id in sorted(results.keys()):
        result = results[worker_id]
        expected = ((worker_id * 10 + 2) * (worker_id + 1))
        actual = result['final_counter']
        
        print(f"å·¥ä½œçº¿ç¨‹ {worker_id}:")
        print(f"  åˆå§‹å€¼: {worker_id * 10}")
        print(f"  é€’å¢2æ¬¡å: {worker_id * 10 + 2}")
        print(f"  ä¹˜ä»¥å› å­ {worker_id + 1}: æœŸæœ›={expected}, å®é™…={actual}")
        print(f"  çº¿ç¨‹ID: {result['thread_id']}")
        print(f"  çŠ¶æ€æ­£ç¡®: {'âœ…' if actual == expected else 'âŒ'}")
        print()
    
    # éªŒè¯æ‰€æœ‰ç»“æœéƒ½æ˜¯æ­£ç¡®çš„
    all_correct = all(
        result['final_counter'] == ((worker_id * 10 + 2) * (worker_id + 1))
        for worker_id, result in results.items()
    )
    
    print("ğŸ‰ å¹¶å‘å®‰å…¨æ€§éªŒè¯:", "âœ… é€šè¿‡" if all_correct else "âŒ å¤±è´¥")
    
    return all_correct


def parallel_processing_demo():
    """å¹¶è¡Œå¤„ç†æ¼”ç¤º"""
    print(f"\nğŸ”„ å¹¶è¡Œå¤„ç†æ¼”ç¤º")
    print("=" * 50)
    
    @node
    def data_source(base_number):
        """æ•°æ®æº"""
        return base_number * 2
    
    @node
    def process_a(data_source):
        """å¤„ç†å™¨A: åŠ æ³•è¿ç®—"""
        time.sleep(0.05)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
        return data_source + 100
    
    @node
    def process_b(data_source):  
        """å¤„ç†å™¨B: ä¹˜æ³•è¿ç®—"""
        time.sleep(0.05)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
        return data_source * 3
    
    @node
    def process_c(data_source):
        """å¤„ç†å™¨C: å¹‚è¿ç®—"""
        time.sleep(0.05)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
        return data_source ** 1.5
    
    # åˆ›å»ºæ‰‡å‡ºæµç¨‹
    parallel_workflow = data_source.fan_out_to([process_a, process_b, process_c])
    
    # æµ‹è¯•å¤šä¸ªè¾“å…¥å€¼
    test_values = [1, 2, 3, 4, 5]
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
        # å¹¶å‘æ‰§è¡Œå¤šä¸ªå·¥ä½œæµç¨‹å®ä¾‹
        futures = []
        
        for i, value in enumerate(test_values):
            future = executor.submit(
                parallel_workflow.run,
                {'base_number': value}
            )
            futures.append((i, value, future))
        
        # æ”¶é›†ç»“æœ
        print("å¤„ç†ç»“æœ:")
        for i, value, future in futures:
            result = future.result()
            parallel_results = result['__parallel_results']
            
            print(f"è¾“å…¥ {value}:")
            print(f"  æ•°æ®æºå¤„ç†å: {value * 2}")
            print(f"  å¤„ç†å™¨A (åŠ æ³•): {parallel_results.get('process_a', 'N/A')}")
            print(f"  å¤„ç†å™¨B (ä¹˜æ³•): {parallel_results.get('process_b', 'N/A')}")
            print(f"  å¤„ç†å™¨C (å¹‚è¿ç®—): {parallel_results.get('process_c', 'N/A')}")
            print()
    
    print("âœ… å¹¶è¡Œå¤„ç†æ¼”ç¤ºå®Œæˆ")


if __name__ == "__main__":
    try:
        # è¿è¡Œå¹¶å‘æ¼”ç¤º
        success = concurrent_demo()
        
        # è¿è¡Œå¹¶è¡Œå¤„ç†æ¼”ç¤º
        parallel_processing_demo()
        
        if success:
            print("\nğŸŠ æ‰€æœ‰æ¼”ç¤ºéƒ½æˆåŠŸå®Œæˆï¼AetherFlowæ¡†æ¶åœ¨å¹¶å‘ç¯å¢ƒä¸‹å·¥ä½œæ­£å¸¸ã€‚")
        else:
            print("\nâš ï¸ å‘ç°é—®é¢˜ï¼Œè¯·æ£€æŸ¥å®ç°ã€‚")
            
    except Exception as e:
        print(f"\nâŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        raise